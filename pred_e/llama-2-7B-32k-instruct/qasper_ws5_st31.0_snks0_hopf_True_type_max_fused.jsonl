{"pred": "Fox News (Document[111]):\"We used a dataset of 1000 Facebook posts from 1000 different Facebook pages, which we scraped from the Facebook Graph API . The posts were collected between 2016 and 2018 . The posts were collected from a variety of pages, including news, entertainment, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics, politics", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "linear context (Document[111]):\"The latent context is a sequence of posts, where each post is a sequence of words . The latent context is used to predict the next post in the sequence . The latent context is represented as a sequence of vectors, where each vector is a sequence of words . The latent context is used to predict the next post in the sequence . The latent context is used to predict the next post in the sequence . The latent context is used to predict the next post in the sequence . The latent context is used to predict the next post in the sequence . The lat", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "F-score (Document[220]):\"The F - score is a harmonic mean of precision and recall . It is used to evaluate the performance of a classifier . It is calculated as follows: F - score = ( precision  × recall) / ( precision + recall) where precision is the ratio of true positives to the total number of true positives and recall is the ratio of true positives to the total number of true positives . The F - score is a measure of the classifier's ability to separate the classifier's ability to separate the classifier's ability to separate the", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "plain LSTM (Bibb)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "unanswerable\n\n\nQuestion: Does jiant support any model?\n\nAnswer: unanswerable\n\nQuestion: Does jiant support any model?\n\nAnswer: unanswerable\n\nQuestion: Does jiant support any model?\n\nAnswer: unanswerable\n\nQuestion: Does jiant support any model?\n\nAnswer: unanswerable\n\nQuestion: Does jiant support any model?\n\nAnswer: unanswerable\n\nQuestion: Does jiant support any model?\n\nAnswer: unanswerable\n\nQuestion: Does jiant support any model?\n\nAnswer: un", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "yes (Based on the article, the experts are not real users, but experts in the field)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "unanswerable\n\n\nQuestion: Does this method help in NERD classification?\n\nAnswer: unanswerable\n\nQuestion: Does this method help in NERD classification?\n\nAnswer: unanswerable\n\nQuestion: Does this method help in NERD classification?\n\nAnswer: unanswerable\n\nQuestion: Does this method help in NERD classification?\n\nAnswer: unanswerable\n\nQuestion: Does this method help in NERD classification?\n\nAnswer: unanswerable\n\nQuestion: Does this method help in NERD classification?\n\nAnswer: un", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Amazon Reviews (Bibar et al., 2017) and Yelp Reviews (Bolukbasi et al., 2017)\n\nQuestion: What is the size of the datasets?\n\nAnswer: 100,000 reviews\n\nQuestion: What is the size of the test set?\n\nAnswer: 100,000 reviews\n\nQuestion: What is the size of the train set?\n\nAnswer: 100,000 reviews\n\nQuestion: What is the size of the validation set?\n", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "12.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (EL 1.27%), 1.27% (", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "transcribed (Document[11]):\"We use the IEEE dataset, which includes audio and text data . The audio data is in the WAV format, and the text data is in the TXT format . The audio data is transcribed into text data using the Google Cloud Speech-to-Text API.\"\n\nAnswer: transcribed (Document[1]):\"We use the IEEE dataset, which includes audio and text data . The audio data is in the WAV format, and the text data is in the TXT format . The audio data is transcribed into text data using the Google Cloud Spe", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "CLUTER (Document[12000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT (Bidirectional Encoder Representations)\n\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer: BERT (Bidirectional Encoder Representations)\n\nAnswer", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "pivot-based methods (BIBM)\n\n\nQuestion: what are the transfer-based methods?\n\nAnswer: transfer-based methods (BIB)\n\nQuestion: what are the transfer-based methods?\n\nAnswer: transfer-based methods (BIB)\n\nQuestion: what are the transfer-based methods?\n\nAnswer: transfer-based methods (BIB)\n\nQuestion: what are the transfer-based methods?\n\nAnswer: transfer-based methods (BIB)\n\nQuestion: what are the transfer-based methods?\n\nAnswer: transfer-based methods (B", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Emotion 17000 (BERT) and Eksp 1700 (Rosetta)\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n\nAnswer: Friends\n", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "several evaluation protocols for each part of the database (Document[11]):\"The paper provides several evaluation protocols for each part of the database . The protocols allow researchers to investigate the performance of the system in different scenarios and conditions.\"\n\nAnswer: The paper provides several evaluation protocols for each part of the database (Document[1]):\"The paper provides several evaluation protocols for each part of the database\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian masks are used to adjust the attention weights. The Gaussian masks are calculated by Equation (DISPLAY_FORMA)\n\nAnswer: Gaussian masks are used to adjust the attention weights. The Gaussian masks are calculated by Equation (DISPLAY_FORMA)\n\nAnswer: Gaussian masks are used to adjust the attention weights.\n\nAnswer: Gaussian masks are used to adjust the attention weights.\n\nAnswer: Gaussian masks are used to adjust the attention weights.\n\nAnswer: Gaussian masks are used to adjust the attention weights.\n\nAnswer: Gaussian masks are", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "unanswerable (Document[10]):\"The system is trained on monolingual English text . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100 million parameters . The system is trained on 100", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "unanswerable\n\n\nQuestion: In what cases does attention agree with alignment?\n\nAnswer: unanswerable\n\nQuestion: In what cases does attention not agree with alignment?\n\nAnswer: unanswerable\n\nQuestion: In what cases does attention agree with alignment?\n\nAnswer: unanswerable\n\nQuestion: In what cases does attention not agree with alignment?\n\nAnswer: unanswerable\n\nQuestion: In what cases does attention agree with alignment?\n\nAnswer: unanswerable\n\nQuestion: In what cases does attention not agree with alignment?\n\nAnswer: unanswerable\n", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "RNN (Recurrent Neural Network) (Document[119]):\"The model is a RNN (Recurrent Neural Network) with a hidden state of size 256 . The input is a sequence of 1024 timesteps, and the output is a sequence of 1024 timesteps . The model is trained on the LibriSpeech dataset, which contains 600 hours of audio data.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "Bi-LST (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirectional LST) (Bidirection", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "2020\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer: This paper proposes a novel framework for summarizing text documents based on the idea of \"abstractive\" summarization. The framework uses a combination of natural language processing techniques and machine learning algorithms to generate summaries that are both informative and concise. The paper also provides a detailed analysis of the strengths and weaknesses of the proposed framework and its limitations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "11110000 (Document[1000]):\"1100\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (SVM)\n\nAnswer: SVM (Support Vector Machine) (", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "BiLSTM (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LSTM) (Bidirectional LST", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Untitled \"word2vec\" BIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIB", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "five keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive keyphrasextractive key", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "yes\n\n\nQuestion: What is the conclusion of the paper?\n\nAnswer: encoder\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: encoder\n\nQuestion: What is the main result of the paper?\n\nAnswer: encoder\n\nQuestion: What is the main conclusion of the paper?\n\nAnswer: encoder\n\nQuestion: What is the main result of the paper?\n\nAnswer: encoder\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: encoder\n\nQuestion: What is the main result of the paper?", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "MIMDB (BIBM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "14,14,14 (Document[10]):\"The dataset contains 14,14,14 tweets, 14,14,14 tweets, and 14,14,14 tweets.\"\n\nAnswer: 14,14,14 (Document[10]):\"The dataset contains 14,14,14 tweets.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "the relevance of other words in the sentence (BIBR)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "BOW (Bag of Words)\n\nQuestion: what was the proposed model?\n\nAnswer: Causal BOW (Causal Bag of Words)\n\nQuestion: what was the performance of the proposed model?\n\nAnswer: 0.75\n\nQuestion: what was the performance of the baseline model?\n\nAnswer: 0.65\n\nQuestion: what was the improvement of the proposed model over the baseline model?\n\nAnswer: 0.1\n\nQuestion: what was the number of parameters in the proposed model?\n\nAnswer: 1", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "29 (Document[19]):\"In this paper, we propose a novel approach to tag recommendation, which is based on the idea of combining tags from different sources . We propose a novel framework, which combines tags from different sources using a novel tag fusion approach . The framework is evaluated on a dataset of 29 tags from different sources, which are annotated on 8,000 books . The framework is able to recommend tags, which are able to recommend tags, which are able to recommend tags, which are able to recommend tags, which are able to recommend tags, which are able to recommend tags", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\nAnswer: end-to-end (BERT)\n\n", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Penn BIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIB", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "unanswerable\n\nQuestion: Do they use clustering?\n\nAnswer: yes\n\nQuestion: Do they use SVM?\n\nAnswer: yes\n\nQuestion: Do they use LDA?\n\nAnswer: yes\n\nQuestion: Do they use DBSCAN?\n\nAnswer: yes\n\nQuestion: Do they use k-means?\n\nAnswer: yes\n\nQuestion: Do they use hierarchical clustering?\n\nAnswer: yes\n\nQuestion: Do they use grid search?\n\nAnswer: yes\n\nQuestion: Do they use grid search?\n\nAnswer:", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "\"However, as discussed in Section SEC, the vocabulary size of the student is limited to the size of the teacher's vocabulary, which is not enough to learn the student's vocabulary. This is not enough to learn the student's vocabulary. This is not enough to learn the student's vocabulary. This is not enough to learn the student's vocabulary. This is not enough to learn the student's vocabulary. This is not enough to learn the student's vocabulary. This is not enough", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word2vec (word2vec)\n\n\nQuestion: What is the accuracy of the baseline method?\n\nAnswer: 75.00\n\nQuestion: What is the accuracy of the best method?\n\nAnswer: 80.00\n\nQuestion: What is the best method?\n\nAnswer: corpus-based approach (corpus-based approach)\n\nQuestion: What is the best method?\n\nAnswer: corpus-based approach (corpus-based approach)\n\nQuestion: What is the best method?\n\nAnswer: corpus-based approach (", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "1.7M ancient Chinese parallel corpus BIBL-CC-1003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "unanswerable\n\n\nArticle: Introduction\nThe answerability of a question is a measure of how likely a question is to be answered. The answerability of a question is a measure of how likely a question is to be answered. The answerability of a question is a measure of how likely a question is to be answered. The answerability of a question is a measure of how likely a question is to be answered. The answerability of a question is a measure of how likely a question is to be answered. The answerability of a question is a measure of how likely a question is to be answered. The answerability", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "words (Document[10]):\"The most predictive features are words, style, and emotion . The most predictive words are \"fake news\", \"alternative facts\", \"post-truth\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake news\", \"fake", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "XNLIR (Bibf)\n\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (Bib)\n\nAnswer: XNLIR (B", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "unsupervised (Document[1109]):\"In NLP, word embeddings are learned from unsupervised data, such as text corpora, and are used to represent words as vectors in a high - dimensional space . The goal is to learn a mapping from words to vectors, such that words that are close in the original space are mapped to vectors that are close in the original space are mapped to vectors that are close in the original space are mapped to vectors that are close in the original space are mapped to vectors that are close in the original space are mapped to vectors that are close in the original space are", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "unanswerable\n\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: un", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "over 450000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "ELMoE (Document[10]):\"ELMoE: We propose a novel few - shot learning model ELMoE, which is based on the combination of the pre-trained language model and the fine - tuned model . The pre-trained language model is used to extract the general knowledge from the large corpus, and the fine - tuned model is used to fine - tune the fine - tune the fine - tune the fine - tune the fine - tune the fine - tune the fine - tune the fine - tune the fine - tune the fine - t", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "251 (Document[16]):\"The dataset consists of 14 subjects, each with 1000 trials, recorded with 251 electrodes . The signals were recorded at a sampling rate of 1000 Hz and were bandpass filtered in the frequency range of 0.01 Hz to 30 Hz . The signals were then downsampled to 100 Hz . The signals were then normalized in the time domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain domain", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Retrieval\n\n\nQuestion: What is the purpose of the Macaw framework?\n\nAnswer: To provide a platform for developing and deploying conversational AI systems.\n\nQuestion: What is the architecture of Macaw?\n\nAnswer: It is a modular architecture that allows for the easy addition and removal of components.\n\nQuestion: What is the user interface of Macaw?\n\nAnswer: It is a command-line interface.\n\nQuestion: What is the retrieval component of Macaw?\n\nAnswer: It is a component that allows for the retrieval of information from a database.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "yes (Document[111]):\"The dataset is based on the Wikipedia dump from 2015-01-01 . The dataset is split into training, validation, and test sets . The dataset is split into 100,000, 10,000, and 10,000 sentences, respectively . The dataset is split into 100,000, 10,000, and 10,000 sentences, respectively . The dataset is split into 100,000, 1", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "unanswerable (Document[111]):\"The corpus consists of 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQuAD (SQuAD)\n\n\nQuestion: What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "SemEval208 (Bibar et al., 2013)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "3000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "Gives a qualitative analysis of the proposed model on various benchmark datasets.\n\nAnswer: unanswerable\n\nQuestion: What are the quantitative results?\n\nAnswer: Gives a quantitative analysis of the proposed model on various benchmark datasets.\n\nAnswer: unanswerable\n\nQuestion: What are the conclusions?\n\nAnswer: Gives conclusions based on the experimental results.\n\nAnswer: unanswerable\n\nQuestion: What are the limitations?\n\nAnswer: Gives limitations of the proposed model.\n\nAnswer: unanswerable\n\nQuestion: What are the future directions?", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "significant (Document[10]):\"Experiments: Paragraph 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "\n\nWe formalize the notion of variance reduction in the context of active learning. We consider a set of instances INLINEFORM0 and a set of labels INLINEFORM1 . We denote the model's prediction for instance INLINEFORM0 as INLINEFORM2 . We denote the true label of INLINEFORM0 as INLINEFORM3 . We denote the model's confidence for INLINEFORM2 as INLINEFORM4 . We denote the model's prediction for INLINEFORM0 as INLINEFORM5 . We denote the model's confidence for INLINEFORM2 as INLINEFORM6 . We denote", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LSTM\n\n\nQuestion: What is the name of the baseline model?\n\nAnswer: seq2seq\n\nQuestion: What is the name of the augmentation method?\n\nAnswer: wordpiece\n\nQuestion: What is the name of the model?\n\nAnswer: LSTM\n\nQuestion: What is the name of the architecture?\n\nAnswer: LSTM\n\nQuestion: What is the name of the baseline model?\n\nAnswer: seq2seq\n\nQuestion: What is the name of the augmentation method?\n\nAnswer: wordpiece\n\n", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "natural language questions (Document[10]):\"The dataset contains 500,0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes (BERT: 3.0)\n\n\nQuestion: What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What is the answer to the question \"What", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "53 (Document(53))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food.com (Bibid: 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "tabular data (tab:intr)\n\n\nQuestion: What is the purpose of this paper?\n\nAnswer: to evaluate the impact of word embeddings on the performance of downstream tasks (tab:intr)\n\nQuestion: What is the main conclusion of the paper?\n\nAnswer: that word embeddings are effective for downstream tasks (tab:intr)\n\nQuestion: What is the main contribution of the paper?\n\n: a new method for evaluating word embeddings (tab:intr)\n\n: a new dataset for evaluating word embeddings (", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "unanswerable\n\n\nQuestion: What is the purpose of the dataset?\n\nAnswer: unanswerable\n\nQuestion: What is the distribution of the data?\n\nAnswer: unanswerable\n\nQuestion: What is the size of the dataset?\n\nAnswer: unanswerable\n\nQuestion: What is the format of the data?\n\nAnswer: unanswerable\n\nQuestion: What is the source of the data?\n\nAnswer: unanswerable\n\nQuestion: What is the annotation method?\n\nAnswer: unanswerable\n\nQuestion: What is the annotation tool?\n\n", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "2500 words (Document[1119]):\"The dataset consists of 1000 texts, with an average length of 50 words and a maximum length of 100 words . The texts were collected from the internet and are annotated with the following tags: 1) 2) 3) 4) 5) 6) 7) 8) 9) 10) 11) 12) 13) 14) 15) 16) 17) 18) 1", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "textual patterns (Document[111]):\"We also propose a method for learning textual patterns from an annotated corpus . The patterns are learned by a combination of a statistical model and a rule-based model . The statistical model is based on a probabilistic model of the annotated text . The rule-based model is based on a set of rules that are learned from the annotated text . The rules are learned by a set of heuristics . The heuristics are learned by a set of heuristics . The heuristics are learned by a set of heuristics . The heuristics", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "unanswerable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "RKS approach proposed in the article is a method to explicitly map the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space to the feature space. The RKS approach explicitly maps the embedding space", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "a variant that does not use ELMo (Bibf) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan) (Inan", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "The results on the FCE datasets are shown in Table TABREF1. The results on the FCE datasets are shown in Table TABREF2. The results on the FCE datasets are shown in Table TABREF3. The results on the FCE datasets are shown in Table TABREF4. The results on the FCE datasets are shown in Table TABREF5. The results on the FCE datasets are shown in Table TABREF6. The results on the FCE datasets are shown in Table TABREF7. The results on the FCE datasets are shown in Table TABREF8.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "none (Document[159]):\"We have not explored the method to any other tasks, but the authors of the paper have used the method to predict the next word in a sentence, and the method has performed well.\"\n\nAnswer: unanswerable\n\nQuestion: What is the name of the paper?\n\nAnswer: tweet2vec (Document[15]):\"The paper is titled \"tweet2vec: Twitter as a corpus for vector space learning\" and is authored by Yoav Goldberg, Yonatan Rudin, and Noa Agmon . The paper", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "seven legal experts (BIBM)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "machine learning (ML) (Document[111]):\"Vietnamese word segmentation is a task of Vietnamese language processing, which is to segment words into their smallest units . Vietnamese word segmentation is a task of Vietnamese language processing, which is to segment words into their smallest units . Vietnamese word segmentation is a task of Vietnamese language processing, which is to segment words into their smallest units . Vietnamese word segmentation is a task of Vietnamese language processing, which is to segment words into their smallest units . Vietnamese word segmentation is a task of Vietnamese language processing, which is to", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Stanford's Named Entity Recognition (NER) model, a state-of-the-art named entity recognition model, and a simple rule-based model (BIBLIOREF0001).\n\nQuestion: what is the name of the ner model?\n\nAnswer: Stanford's Named Entity Recognition (NER) model (BIBLIREF0000000000000000000000000000000000000000000000", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WN/WN1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "Last State\n\n\nQuestion: What is the name of the dataset used in the paper?\n\nAnswer: Harassment Dataset\n\nQuestion: What is the name of the attention mechanism used in the paper?\n\nAnswer: Self-Attention\n\nQuestion: What is the name of the classification model used in the paper?\n\nAnswer: Multi-Class Classification\n\nQuestion: What is the name of the RNN model used in the paper?\n\nAnswer: RNN\n\nQuestion: What is the name of the attention mechanism used in the paper?\n\nAnswer: Self-Attention\n", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "three (Document[111]):\"We experimented with three different types of cyberbullying: personal attacks, sexual harassment, and hate speech . We used three different social media platforms: Twitter, Reddit, and Wikipedia . We used three different datasets: Former President Barack Obama's tweets, the 2016 US Presidential Election, and the 2016 US Presidential Election results.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "yes\n\n\nQuestion: Do they use NLP techniques?\n\nAnswer: yes\n\nQuestion: Do they use machine learning?\n\nAnswer: yes\n\nQuestion: Do they use topic modeling?\n\nAnswer: yes\n\nQuestion: Do they use clustering?\n\nAnswer: yes\n\nQuestion: Do they use classification?\n\nAnswer: yes\n\nQuestion: Do they use regression?\n\nAnswer: yes\n\nQuestion: Do they use time series?\n\nAnswer: no\n\nQuestion: Do they use spatial?\n\nAnswer: no\n\nQuestion: Do they use", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "an existing annotated Twitter dataset (BIBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an existing annotated Twitter dataset (IBM)\n\nAnswer: an", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "Nguni (Document[1]):\"The Nguni language is a Bantu language spoken in the Democratic Republic of the Congo . It is one of the languages of the Nguni subgroup of the Sotho - Tswana languages . Nguni is a language isolate.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "IMDb dataset of movie reviews (BIBMREF0)\n\nArticle: The dataset used for sentiment analysis is the IMDb dataset of movie reviews (BIBMREF0).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "89.6%\n\n\nQuestion: What was the classifier's performance?\n\nAnswer: 89.6%\n\nQuestion: What was the classifier's performance?\n\nAnswer: 89.6%\n\nQuestion: What was the classifier's performance?\n\nAnswer: 89.6%\n\nQuestion: What was the classifier's performance?\n\nAnswer: 89.6%\n\nQuestion: What was the classifier's performance?\n\nAnswer: 89.6%\n\nQuestion: What was", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "K-meansurable Event Extraction (K-ME)\n\n\nAnswer: K-meansurable Event Extraction (K-ME)\n\nAnswer: K-meansurable Event Extraction (K-ME)\n\nAnswer: K-meansurable Event Extraction (K-ME)\n\nAnswer: K-meansurable Event Extraction (K-ME)\n\nAnswer: K-meansurable Event Extraction (K-ME)\n\nAnswer: K-meansurable Event Extraction (K-ME)\n\nAnswer: K-meansurable Event Extraction", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "English (English (en)), German (Deutsch), French (Français), Italian (Italiano), Polish (Polski), Russian (русский), Spanish (Español)\n\nAnswer:\nEnglish (English (en)), German (Deutsch), French (Français), Italian (Italiano), Polish (Polski), Russian (русский), Spanish (Español)\n\nAnswer:\nEnglish (English (en)), German (Deutsch), French (Français), Italian (Italiano), Polish (Polski), Russian (русский), Spanish (Español)\n\nAnswer:\nEnglish (", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "Table TABREF1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "unanswerable\n\n\nQuestion: Is the lexicon the same for all languages?\n\nAnswer: unanswerable\n\nQuestion: Is the lexicon the same for all languages?\n\nAnswer: unanswerable\n\nQuestion: Is the lexicon the same for all languages?\n\nAnswer: unanswerable\n\nQuestion: Is the lexicon the same for all languages?\n\nAnswer: unanswerable\n\nQuestion: Is the lexicon the same for all languages?\n\nAnswer: unanswerable\n\nQuestion: Is the lexicon the same for all languages?\n\nAnswer: un", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "average GloVe\n\n\nQuestion: What is the correlation between SBERT and GloVe?\n\nAnswer: 0.7\n\nQuestion: What is the correlation between SBERT and GloVe?\n\nAnswer: 0.7\n\nQuestion: What is the correlation between SBERT and GloVe?\n\nAnswer: 0.7\n\nQuestion: What is the correlation between SBERT and GloVe?\n\nAnswer: 0.7\n\nQuestion: What is the correlation between SBERT and GloVe?\n\nAnswer: 0", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "Sentiment analysis (SentEval)\n\n\nAnswer: Sentiment analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)\n\nAnswer: Sentic analysis (SentEval)", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "40,000 (Document[19]):\"The vocabulary is a set of words that are used to represent the concepts in the dataset . The vocabulary is typically a small set of words that are used to represent the concepts in the dataset . The vocabulary is typically a small set of words that are used to represent the concepts in the dataset . The vocabulary is typically a small set of words that are used to represent the concepts in the dataset . The vocabulary is typically a small set of words that are used to represent the concepts in the dataset .", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Contextualized features (i.e. tweet embeddings)\n\nAnswer: Contextualized features (e.g. embeddings)\n\nAnswer: Contextualized features (e.g. embeddings)\n\nAnswer: Contextualized features (e.g. embeddings)\n\nAnswer: Contextualized features (e.g. embeddings)\n\nAnswer: Contextualized features (e.g. embeddings)\n\nAnswer: Contextualized features (e.g. embeddings)\n\nAnswer: Contextualized embeddings\n", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "yes\n\n\nQuestion: Do they use pre-trained embeddings?\n\nAnswer: yes\n\nQuestion: Do they use pre-trained embeddings?\n\nAnswer: yes\n\nQuestion: Do they use pre-trained embeddings?\n\nAnswer: yes\n\nQuestion: Do they use pre-trained embeddings?\n\nAnswer: yes\n\nQuestion: Do they use pre-trained embeddings?\n\nAnswer: yes\n\nQuestion: Do they use pre-trained embeddings?\n\nAnswer: yes\n\nQuestion: Do they", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "yes\n\n\nQuestion: Do they use machine learning to generate maps?\n\nAnswer: yes\n\nQuestion: Do they use a web-based platform to generate maps?\n\nAnswer: yes\n\nQuestion: Do they use a mobile app to generate maps?\n\nAnswer: no\n\nQuestion: Do they use a desktop application to generate maps?\n\nAnswer: no\n\nQuestion: Do they use a web-based platform to generate maps?\n\nAnswer: yes\n\nQuestion: Do they use a mobile app to generate maps?\n\nAnswer: no\n\nQuestion: Do they use a desktop", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "0.67 (unanswerable)\n\n\nQuestion: What is the best performing model among all submissions?\n\nAnswer: 0.67 (unanswerable)\n\nQuestion: What is the best performing model among all submissions?\n\nAnswer: 0.67 (unanswerable)\n\nQuestion: What is the best performing model among all submissions?\n\nAnswer: 0.67 (unanswerable)\n\nQuestion: What is the best performing model among all submissions?\n\nAnswer: 0.67 (unanswerable)\n", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "DTA188888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "KNN (BIBM)\n\n\nQuestion: What is the most effective classifier?\n\nAnswer: KNN (IBM)\n\nQuestion: What is the most effective classifier?\n\nAnswer: KNN (IBM)\n\nQuestion: What is the most effective classifier?\n\nAnswer: KNN (IBM)\n\nQuestion: What is the most effective classifier?\n\nAnswer: KNN (IBM)\n\nQuestion: What is the most effective classifier?\n\nAnswer: KNN (IBM)\n\nQuestion: What is the most effective class", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "Extended CNN (Document[10]):\"In this paper, we propose a new context representation for CNNs, which we call Extended CNN (ER-CNN). The ER-CNN is based on the original CNN, but it is extended by adding a new layer, which we call the Extended Layer . The Extended Layer is a combination of the original CNN and a new layer, which we call the Extended Layer . The Extended Layer is a combination of the original CNN and a new layer, which we call the Extended Layer . The Extended Layer is a combination", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "multi-layered neural network (CNN) architecture (BIBMREF:1)\n\nAnswer: multi-layered neural network (BIBMREF:1)\n\nAnswer: multi-layered neural network (BIBMREF:1)\n\nAnswer: multi-layered neural network (BIBMREF:1)\n\nAnswer: multi-layered neural network (BIBMREF:1)\n\nAnswer: multi-layered neural network (BIBMREF:1)\n\nAnswer: multi-layered neural network (BIBMREF:1)\n", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "over 45,000 articles and over 1000 scholarly papers BIBREF20, BIBREF21, BIBREF22, BIBREF23, BIBREF24, BIBREF25, BIBREF26, BIBREF27, BIBREF28, BIBREF29, BIBREF30, BIBREF31, BIBREF32, BIBREF33, BIBREF34, BIBREF35, BIBREF36, BIBREF37, B", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "2690000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "BIBM (Bidirectional Markov Model)\n\n\nQuestion: what is the main motivation of the paper?\n\nAnswer: to learn a probabilistic model of the sentence\n\nQuestion: what is the main contribution of the paper?\n\nAnswer: a probabilistic model of the sentence\n\nQuestion: what is the main method of the paper?\n\nAnswer: a probabilistic model of the sentence\n\nQuestion: what is the main result of the paper?\n\nAnswer: a probabilistic model of the sentence\n\nQuestion: what is the main conclusion of the paper?\n\nAnswer", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "The word \"backoff\" is used to describe a situation where a person is no longer able to use a device or service. The word \"backoff\" is used to describe a situation where a person is no longer able to use a device or service. The word \"backoff\" is used to describe a situation where a person is no longer able to use a device or service. The word \"backoff\" is used to describe a situation where a person is no longer able to use a device or service. The word \"backoff\" is used to describe a situation where a person is no longer able to use a device or", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "DSTC (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands) (Documentation of Spoken Commands", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "BLEU (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En) (Bio-Lang-En", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "AutoJudge (BIBREFREF)\n\n\nQuestion: what is the purpose of the paper?\n\nAnswer: to introduce a new method for predicting the outcome of a civil case (BIBREF)\n\nQuestion: what is the main contribution of the paper?\n\nAnswer: a new method for predicting the outcome of a civil case (BIBREF)\n\nQuestion: what is the main problem addressed in the paper?\n\nAnswer: predicting the outcome of a civil case (BIBREF)\n\nQuestion: what is the main approach used in the paper?\n\nAnswer", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "surface features (e.g. POS, Nouns, Vbs, Adjs, Nouns, Adjectives, and Adverbs) and morphological features (e.g. root, stem, and suffix) (BibTeX: [1]).\n\nAnswer: surface features (e.g. POS, Nouns, Vbs, Adjs, and Adjectives) and morphological features (BibTeX: [1]).\n\nAnswer: surface features (e.g. POS, Nouns, Vbs, Adjs, Adjects, Adject", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "the INTERSECTION\n\n\nQuestion: What is the name of the method that is used to align the dimensions of the word embeddings?\n\nAnswer: The proposed method is called \"Conceptual Dimensionality Alignment\" (CDA)\n\nQuestion: What is the name of the method that is used to align the dimensions of the word embeddings?\n\nAnswer: The proposed method is called \"Conceptual Dimensional Alignment\" (CDA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "English (EN)\n\n\nQuestion: what is the domain of the data?\n\nAnswer: EuroParl (EN)\n\nQuestion: what is the language pair?\n\nAnswer: English (EN)\n\nQuestion: what is the language pair?\n\nAnswer: English (EN)\n\nQuestion: what is the language pair?\n\nAnswer: English (EN)\n\nQuestion: what is the language pair?\n\nAnswer: English (EN)\n\nQuestion: what is the language pair?\n\nAnswer: English (EN)\n\nQuestion: what is the language pair?\n", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "unanswerable\n\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\nAnswer: unanswerable\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\nAnswer: unanswerable\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\nAnswer: unanswerable\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\nAnswer: unanswerable\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\nAnswer: unanswerable\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\nAnswer: unanswerable\n\nQuestion:", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "disinformation and misinformation (Document[1119]):\"The two main types of information that we have been discussing are disinformation and misinformation . The first one is the intentional spread of false information, while the second one is the intentional spread of false information . The first one is the intentional spread of false information . The first one is the intentional spread of false information . The first one is the intentional spread of false information . The first one is the intentional spread of false information . The first one is the intentional spread of false information . The first one is the first one is the", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "Coin Text (Bibre)\n\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre)\n\nAnswer: Coin Text (Bibre", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F1 and F2\n\n\nQuestion: What is the name of the model?\n\nAnswer: INLINE\n\nQuestion: What is the name of the dataset?\n\nAnswer: INLINE\n\nQuestion: What is the name of the model?\n\nAnswer: INLINE\n\nQuestion: What is the name of the dataset?\n\nAnswer: INLINE\n\nQuestion: What is the name of the model?\n\nAnswer: INLINE\n\nQuestion: What is the name of the dataset?\n\nAnswer: INLINE\n\nQuestion: What is the name of the model?\n\n", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "the bias in the process of collecting data (Document[22222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "Conclusion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "\"We propose to use a modified objective function that includes an additional term that favors the concept of the word embeddings. This term is a linear combination of the input word embeddings and a set of predefined word embeddings. The predefined word embeddings are obtained from a set of word embeddings that are obtained from a set of word embeddings that are obtained from a set of word embeddings that are obtained from a set of word embeddings that are obtained from a set of word embeddings that are obtained from a set of word embeddings that are obtained from a set", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "unanswerable\n\n\nQuestion: Do they use any other languages?\n\nAnswer: unanswerable\n\nQuestion: Do they use any other languages?\n\nAnswer: unanswerable\n\nQuestion: Do they use any other languages?\n\nAnswer: unanswerable\n\nQuestion: Do they use any other languages?\n\nAnswer: unanswerable\n\nQuestion: Do they use any other languages?\n\nAnswer: unanswerable\n\nQuestion: Do they use any other languages?\n\nAnswer: unanswerable\n\nQuestion: Do they use any other languages?\n\nAnswer: un", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "novel document-level representation of text (Document[1119]):\"We propose a novel document-level representation of text, which we call the \"document embeddings\" (DE). DEs are learned from text corpora and are used to encode the meaning of text . DEs are learned from text corpora and are used to encode the meaning of text . DEs are learned from text corpora and are used to encode the meaning of text . DEs are learned from text corpora and are used to encode the meaning of text . DEs are learned from text corpora and are used to encode the meaning", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "The authors propose an adaptive model that learns to the input and learns to the task at hand. The authors propose an adaptive model that learns to the input and learns to the task at hand. The authors propose an adaptive model that learns to the input and learns to the task at hand. The authors propose an adaptive model that learns to the input and learns to the task at hand. The authors propose an adaptive model that learns to the input and learns to the task at hand. The authors propose an adaptive model that learns to the input and learns to the", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "0.5 (Document[10]):\"The morphology of the attention mechanism is improved by reducing the number of layers from 4 to 3 . The number of attention heads is reduced from 8 to 6 . The number of attention layers is reduced from 3 to 2 . The number of attention heads is reduced from 8 to 6 . The number of attention heads is reduced from 8 to 6 . The number of attention heads is reduced from 8 to 6 . The number of attention heads is reduced from 8 to 6 . The number of attention heads is reduced from 8", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "sentence (Document[111]):\"An instance is a sentence or an IE tuple .\"\n\nAnswer: sentence\n\nQuestion: What is a sentence?\n\nAnswer: \"A sentence is a collection of words that expresses a complete thought .\" (Document[11]):\"A sentence is a collection of words, called a clause, that expresses a complete thought . A sentence is a grammatically complete unit of language . It is a self - contained unit consisting of words, which is either a phrase or clause . A sentence is a complete expression in a language . It is a complete expression that", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "personalized (Document[179]):\"Anti-social events are a subset of antisocial events . Antisocial events are events that are not personalized to a specific user . Antisocial events are events that are not personalized to a specific user . Antisocial events are events that are not personalized to a specific user . Antisocial events are events that are not personalized to a specific user . Antisocial events are events that are not personalized to a specific user . Antisocial events are events that are not personalized to a specific user . Antisocial events are events that", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "We randomly split the data into training and validation sets in a ratio of 8:2. The training set contains 10000 cases and the validation set contains 2000 cases. (BIBREF1)\n\nAnswer: 10000\n\nAnswer: 10000\n\nAnswer: 10000\n\nAnswer: 10000\n\nAnswer: 10000\n\nAnswer: 10000\n\nAnswer: 10000\n\nAnswer: 10000", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "unanswerable\n\n\nQuestion: How do they evaluate the grammaticality of the output?\n\nAnswer: unanswerable\n\nQuestion: How do they evaluate the grammaticality of the output?\n\nAnswer: unanswerable\n\nQuestion: How do they evaluate the grammaticality of the output?\n\nAnswer: unanswerable\n\nQuestion: How do they evaluate the grammaticality of the output?\n\nAnswer: unanswerable\n\nQuestion: How do they evaluate the grammaticality of the output?\n\n: unanswerable\n\nQuestion: How", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "18.2%\n\n\nQuestion: What is the best performance of the model?\n\nAnswer: 6.8%\n\nQuestion: What is the best performance of the model?\n\nAnswer: 6.8%\n\nQuestion: What is the best performance of the model?\n\nAnswer: 6.8%\n\nQuestion: What is the best performance of the model?\n\nAnswer: 6.8%\n\nQuestion: What is the best performance of the model?\n\nAnswer: 6.8%\n\nQuestion: What is the best performance of the", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "unanswerable\n\n\nQuestion: What is the main conclusion of the paper?\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: unanswerable\n\nQuestion: What is the main methodology of the paper?\n\nAnswer: unanswerable\n\nQuestion: What is the main result of the paper?\n\nAnswer: unanswerable\n\nQuestion: What is the main hypothesis of the paper?\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: unanswerable\n\nQuestion", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "Joint (Document[1]):\"The proposed model is a joint model, combining a visual feature extraction model with a text feature extraction model . The visual feature extraction model is based on a convolutional neural network, which is trained on the ImageNet dataset . The text feature extraction model is based on a recurrent neural network, which is trained on the Wikipedia dataset . The joint model is trained on the same dataset as the two individual models.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "JaRuK (200000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "Layer 1: the set of nodes, i.e. the set of tweets, the set of users, the set of retweets, the set of mentions, the set of hashtags, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls, the set of urls", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "ELMoS (ELMoS)\n\n\nQuestion: What is the best model?\n\nAnswer: ELMoS (ELMoS)\n\nQuestion: What is the best model?\n\nAnswer: ELMoS (ELMoS)\n\nQuestion: What is the best model?\n\nAnswer: ELMoS (ELMoS)\n\nQuestion: What is the best model?\n\nAnswer: ELMoS (ELMoS)\n\nQuestion: What is the best model?\n\nAnswer: ELMoS (ELMoS)\n\nQuestion: What is the best model", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "relation extraction (Document[19]):\"KBs are a collection of knowledge, which can be used to answer questions . The KBs are typically represented as a set of triples, where each triple consists of a head entity, a tail entity, and a relation entity . The relation entity is typically a string that describes the relation between the head and tail entities . The relation entity is used to define the meaning of the triple . The relation entity is typically a string that describes the relation between the head and tail entities . The relation entity is typically a string that describes the relation between the head and tail entities . The relation", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "BIBREF7 (BIBREF7)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "BioASQ (BioASQ) is a dataset of biomedical questions and answers. It is a collection of 100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "TACL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The word \"importance\" is used to describe the importance of a word in a given context. The word \"importance\" is used to describe the importance of a word in a given context. The word \"importance\" is used to describe the importance of a word in a given context. The word \"importance\" is used to describe the importance of a word in a given context. The word \"importance\" is used to describe the importance of a word in a given context. The word \"importance\" is used to describe the importance of a word in a given context. The word \"importance\" is used", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "BIBREF00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "significant improvement (Document[26]):\"We show significant improvement in both low data regimes and high data regimes . We show that our method is robust to different types of data augmentation and different data augmentation strategies . We show that our method is robust to different types of data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and different data augmentation and", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "multiple choice (MC) (Document[29]):\"The paper focuses on the task of multiple choice (MC) question answering, which is a fundamental component of many downstream NLP tasks, including reading comprehension, question answering, and machine translation . The paper presents a new framework for MC question answering, which is based on a novel architecture for language modeling, which is based on a novel architecture for language modeling, which is based on a novel architecture for language modeling, which is based on a novel architecture for language modeling, which is based on a novel architecture for language modeling, which is based", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[159]):\"Waseem (Document[15", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "Transformer (Document[1119]):\"We evaluate our approach on two popular NMT models, Transformer and RNN, and two different datasets, Chinese--English and English--Japanese . We also conduct experiments on a different model architecture, the RNN model, to show that our approach is not limited to the Transformer model.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "F1-score (Section SECREF1)\n\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: A new evaluation metric for keyphrase extraction (Section SEC1)\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: A new evaluation metric for keyphrase extraction (Section SEC1)\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: A new evaluation metric for keyphrase extraction (Section", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "unanswerable (Document[11000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "2-gram (BIBM)\n\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n\nAnswer: 2-gram (BIBM)\n", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "professional translation (§SECREF)\n\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF)\n\nAnswer: professional translation (§SECREF", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "end-to-end (Document[12]):\"Knowledge is power, and KAR is a knowledge - based model that is based on the end - to - end architecture . It is a hybrid model that combines the strengths of both the neural network and the CRF model . The neural network is used to extract the features from the input text, and the CRF model is used to predict the labels from the features . The CRF model is a probabilistic model that is used to predict the labels from the features . The CRF model is a probabilistic model that is used to predict the labels", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Acknowledgments\n\nThanks to ITS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "Human-generated dialogues are annotated with HITs, which are used to model character traits.\n\nAnswer: unanswerable\n\nQuestion: How does the dataset model character traits?\n\nAnswer: Human-generated dialogues are annotated with HITs, which are used to model character traits.\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer:", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "Reuters database (Bibf)\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer: The main contribution of this paper is to propose a new method for text classification based on the attention mechanism, which outperforms the state-of-the-art methods on the Reuters database (Bibf). (Bibf)\n\nQuestion: What is the main contribution of this paper?\n\nAnswer: The main contribution of this paper is to propose a new method for text classification based on the attention mechanism, which outperforms the state-of-the-t-", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "Table TABREF2666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "By examining the tweets of the users who misclassified the tweets, we can see that the users who misclassified the tweets are mostly from the United States, and the United Kingdom. The tweets that are misclassified are mostly from the African countries, and the Middle East countries. The tweets that are misclassified are mostly from the Asian countries. The tweets that are misclassified are mostly from the European countries. The tweets that are misclassified are mostly from the South American countries. The tweets that are misclassified are mostly from the African countries. The tweets that", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "Web\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: Improve\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: Improve\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: Improve\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: Improve\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: Improve\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: Improve\n\nQuestion: What", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "spellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingellingelling", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "We first crawl 600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "The global context refers to the entire document, while the local context refers to the sentence or paragraph in which the target word appears.\n\nAnswer: global context refers to the entire document, while local context refers to the sentence or paragraph in which the target word appears.\n\nAnswer: global context refers to the entire document, while local context refers to the sentence or paragraph in which the target word appears.\n\nAnswer: global context refers to the entire document, while local context refers to the sentence or paragraph in which the target word appears.\n\nAnswer: global context refers to the entire document, while local context refers to the", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Knowledge Base Question Answering (KBQA) (Document[10]):\"KBQA is a task of automatically answering questions from a knowledge base . The task is to answer questions from a knowledge base, which is a collection of facts . The knowledge base is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection of facts, which is a collection", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They used LDA and Gibbs Sampling to evaluate IS and AUC.\n\n\nQuestion: What is the main goal of this paper?\n\nAnswer: To present a taxonomy of LDA methods and evaluate the performance of LDA methods on DBpedia.\n\nQuestion: What is the main contribution of this paper?\n\nAnswer: The main contribution of this paper is to present a taxonomy of LDA methods and evaluate the performance of LDA methods on DBpedia.\n\nQuestion: What is the main goal of this paper?\n\nAnswer: To present a taxonomy of LDA methods", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "yes (Document[12]):\"The authors hypothesize that humans' robustness to noise is due to their general knowledge . They propose that the general knowledge of humans can help them to understand the noise in the data, and thus make better predictions . They propose a method that uses a pre-trained language model to extract general knowledge from a large corpus of text, and then use this general knowledge to make better predictions . They use a pre-trained language model to extract to extract to extract to extract to extract to extract to extract to extract to extract to extract to extract to extract to extract to extract to extract", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "33.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "unanswerable\n\n\nQuestion: What was the BioASQ system?\n\nAnswer: unanswerable\n\nQuestion: What was the BioASQ system?\n\nAnswer: unanswerable\n\nQuestion: What was the BioASQ system?\n\nAnswer: unanswerable\n\nQuestion: What was the BioASQ system?\n\nAnswer: unanswerable\n\nQuestion: What was the BioASQ system?\n\nAnswer: unanswerable\n\nQuestion: What was the BioASQ system?\n\nAnswer: unanswerable\n\nQuestion: What was the BioASQ", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "unanswerable\n\n\nQuestion: What was their highest score for MRR?\n\nAnswer: 0.61\n\nQuestion: What was their highest score for F1?\n\nAnswer: 0.61\n\nQuestion: What was their highest score for Precision?\n\nAnswer: 0.61\n\nQuestion: What was their highest score for Recall?\n\nAnswer: 0.61\n\nQuestion: What was their highest score for F1?\n\nAnswer: 0.61\n\nQuestion: What was their highest score for Precision", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "BLEVREF0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "unanswerable\n\n\nAnswer: unanswerable\n\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer: unanswerable\n\nAnswer:", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Cyber Attack (Cyber Attack)\n\n\nQuestion: What is the purpose of the paper?\n\nAnswer: The purpose of the paper is to demonstrate the effectiveness of the proposed method in real-world scenarios.\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: The main contribution of the paper is the development of a novel method for event extraction and event-based anomaly detection in real-world datasets.\n\nQuestion: What is the main focus of the paper?\n\nAnswer: The main focus of the paper is the development of a novel method for event extra", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "We used machine learning methods to predict the RASK score. We used a dataset of 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conditional sequence-to-sequence model (Seq2Seq) BLEU-based model (BLEU)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "the optimization challenge of learning a neural network that is not invertible (i.e., the Jacobian of the neural network is not full rank) (BIBREFSEC1)\n\nAnswer: The invertibility condition is a condition that is used to ensure that the neural network is invertible. (BIBREFSEC1)\n\nAnswer: The invertibility condition is a condition that is used to ensure that the neural network is invertible. (BIBREFSEc1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Logistic regression (Bibdf) (Document[111]):\"The proposed approach is based on a weakly supervised learning framework, where the labeled data is used to train a classifier, which is then used to predict the class of the unlabeled data . The classifier is trained using a logistic regression model (LR) and a logistic regression model (LR) and a logistic regression model (LR) and a logistic regression model (LR) and a logistic regression model (LR) and a logistic regression model (LR) and a logistic regression model (LR) and", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "INLINEFORM0 (Document[1119]):\"We construct a large scale real-world dataset for the divorce prediction task . The dataset contains 1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "MCQ (Multiplete Choice Questions)\n\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Choice Questions)\n\nAnswer: MCQ (Multiplete Cho", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "Back-translation (BT)\n\n\nAnswer: Back-translation (BT)\n\nQuestion: what methods were used to improve the quality of the translation?\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-translation (BT)\n\nAnswer: Back-trans", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "significant\n\n\nQuestion: What is the main conclusion of the article?\n\nAnswer: The proposed model outperforms the baseline model in terms of Hits@10 and Hits@50.\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: The proposed model outperforms the baseline model in terms of Hits@10 and Hits@50.\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: The proposed model outperforms the baseline model in terms of Hits@10 and Hits@10 and", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "The dataset is a collection of tweets from Twitter, which are annotated with their offensive nature. The dataset is annotated with 10 different offensive labels, which are: 1. Vulgar 2. Sexual 3. Violence 4. Racism 5. Homophobia 6. Homosexuality 7. Transphobia 8. Disability 9. Ageism (Document[10]):\"The dataset is a collection of tweets from Twitter, which are annotated with their offensive nature. The dataset is annotated with their", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The authors show that their policy generalizes better than the policy trained on the original dataset by showing that the agent is able to solve the task in a zero-shot manner. (Section 5.2.2)\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: The main contribution of the paper is to show that the policy trained on the First Text Games generalizes better than the policy trained on the original dataset. (Section 5.2)\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution of the paper?\n\nAnswer", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "To investigate the impact of gender and news media on the perception of the public and the political actors. (BIBR)\n\nQuestion: What is the main goal of the study?\nAnswer: To investigate the impact of gender and news media on the perception of the public and political actors (BIBR)\n\nQuestion: What is the main goal of the study?\nAnswer: To investigate the impact of gender and news media on the perception of the public and political actors (BIBR) (BIBR) (BIBR) (BIBR) (BIBR) (B", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "A predictive model that classifies a user comments as either positive or negative.\n\n\nQuestion: What is the purpose of the predictive model?\n\nAnswer: To classify user comments as either positive or negative.\n\nQuestion: How does the predictive model work?\n\nAnswer: The predictive model uses a machine learning algorithm to analyze the content of user comments and predict whether they are positive or negative.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "yes\n\n\nQuestion: What is the name of the dataset?\n\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\nAnswer: Wikipedia\n\nQuestion: What is the name of the dataset?\n", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "MPQA (BibTeX)\n\n\nQuestion: What is the state-of-the-art system?\n\nAnswer: MPQA (BibTeX)\n\nQuestion: What is the state-of-the-art system?\n\nAnswer: MPQA (BibTeX)\n\nQuestion: What is the state-of-the-art system?\n\nAnswer: MPQA (BibTeX)\n\nQuestion: What is the state-of-the-art system?\n\nAnswer: MPQA (BibTeX)\n\nQuestion: What is the", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "They propose a method to automatically detect the under-translated words in a given text. The method is based on the word importance scores estimated by the word attribution model. The scores are calculated by multiplying the word frequency with the inverse of the word length. The words with the highest scores are considered as the most important words. The method is applied to the Chinese text corpus. The method is based on the Chinese text corpus. The method is based on the Chinese text corpus. The method is based on the Chinese text corpus. The method is based on the Chinese text corpus. The method is based on", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "Wikipedia (Bibdfref)\n\n\nQuestion: What is the main goal of the model?\n\nAnswer: forecasting the number of articles (Bibdf)\n\nQuestion: What is the main challenge of the model?\n\nAnswer: the lack of labeled data (Bibdf)\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: introducing a new model for forecasting the number of articles (Bibdf)\n\nQuestion: What is the main limitation of the model?\n\nAnswer: the lack of labeled data (Bibdf)", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "yes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "EuroParl (BIBF)\n\n\nArticle: \nThe new EuroParl dataset is a parallel corpus of the EuroParl dataset, which consists of 100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "yes\n\n\nQuestion: What is the F1 score?\n\nAnswer: a metric for model performance on a dataset, calculated by taking the harmonic mean of precision and recall\n\nQuestion: What is the macro F1 score?\nAnswer: a metric for model performance on a dataset, calculated by taking the average of the F1 scores of all the classes in the dataset\n\nQuestion: What is the accuracy?\n\nAnswer: a metric for model performance on a dataset, calculated by taking the number of correctly classified samples and dividing by the total number of samples\n\n\n\n\n\n\n\n\n", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "a matrix that shows the co-occurrence of a word in a corpus (Document, Section SECREF000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": "precision, recall, F1-score (Document[37]):\"Evaluation Metrics   Precision   Recall   F1 - score   Accuracy   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support   Support  ", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": "unanswerable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": "by difficulty (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (Bibid) (", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": "approx. 2,1000\n\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,100\n\nAnswer: 2,", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": "yes\n\n\nQuestion: What is the dataset used in the paper?\n\nAnswer: de-identified data\n\nQuestion: What is the dataset used in the paper?\n\nAnswer: de-identified data\n\nQuestion: What is the dataset used in the paper?\n\nAnswer: de-identified data\n\nQuestion: What is the dataset used in the paper?\n\nAnswer: de-identified data\n\nQuestion: What is the dataset used in the paper?\n\nAnswer: de-identified data\n\nQuestion: What is the dataset used in the paper?\n\nAnswer", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": "yes (Section SECREF0)\n\n\nQuestion: What is the function of the bidirectional GRU?\n\nAnswer: bidirectional GRU is a variant of GRU that allows for bidirectional connections between the input and output of the model (Section SECREF0)\n\nQuestion: What is the function of the bidirectional GRU?\n\nAnswer: bidirectional GRU is a variant of GRU that allows for bidirectional connections between the input and output of the model (Section SECREF0)\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": "ROU\n\n\nQuestion: What is the main conclusion of the article?\n\nAnswer: The article discusses the use of a new evaluation metric, ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based on the idea of ROU, which is based", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": "(1) Naive (2) mage (3) Naive (4) Naive (5) Naive (6) Naive (7) Naive (8) Naive (9) Naive (10) Naive (11) Naive (12) Naive (13) Naive (14) Naive (15) Naive (16) Naive (17) Naive (18) Naive (19) Naive (20) Naive (21) Naive (22) Naive (23) Na", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": "59.4%\n\n\nQuestion: What is the name of the system that is the best performing?\n\nAnswer: Joint\n\nQuestion: What is the name of the system that is the worst performing?\n\nAnswer: Inception\n\nQuestion: What is the name of the system that is the second best performing?\n\nAnswer: Inception\n\nQuestion: What is the name of the system that is the second worst performing?\n\nAnswer: Doc\n\nQuestion: What is the name of the system that is the third best performing?\n\nAnswer: Doc\n\nQuestion: What", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": "word2vec\n\n\nQuestion: What is the goal of the paper?\n\nAnswer: to explore the use of second order word embeddings in the context of biomedical text\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: The main contribution of the paper is to explore the use of second order word embeddings in the context of biomedical text.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": "US and Italian\n\n\nQuestion: What is the main goal of the paper?\n\nAnswer: To analyze the diffusion of disinformation on Twitter\n\nQuestion: What is the main methodology used in the paper?\n\nAnswer: Network analysis and machine learning\n\nQuestion: What is the main conclusion of the paper?\n\nAnswer: Disinformation spreads faster and more effectively on Twitter than on other platforms\n\nQuestion: What are the main limitations of the paper?\n\nAnswer: The study only focuses on English-speaking users and does not consider the impact of disinformation on other languages\n\n:", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": "The political leaders and their followers have different profile attributes. The political leaders have more followers and more tweets. The followers have less followers and less tweets.\n\nAnswer: yes\n\nAnswer: The political leaders have more followers and more tweets.\n\nAnswer: yes\n\nAnswer: The political leaders have more followers and more tweets.\n\nAnswer: yes\n\nAnswer: The political leaders have more followers and more tweets.\n\nAnswer: yes\n\nAnswer: The political leaders have more followers and more tweets.\n\nAnswer: yes\n\nAnswer", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": "In a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a human study, we show that a", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": "F1 (Section SECREF1)\n\n\nQuestion: What is the dataset used in the paper?\n\nAnswer: Propaganda (Section SECREF1)\n\nQuestion: What is the task?\n\nAnswer: Sentiment Analysis (Section SECREF1)\n\nQuestion: What is the model?\n\nAnswer: BERT (Section SECREF1)\n\nQuestion: What is the result?\n\nAnswer: 2nd place (Section SECREF1)\n\nQuestion: What is the baseline?\n\nAnswer: LSTM (Section SECREF", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": "unanswerable\n\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes\n\nQuestion: Do they report results only on English data?\n\nAnswer", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": "5000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": "unanswerable\n\n\nQuestion: Do they recommend using a pivot?\n\nAnswer: unanswerable\n\nQuestion: Do they recommend using a pivot?\nAnswer: unanswerable\n\nQuestion: Do they recommend using a pivot?\nAnswer: unanswerable\n\nQuestion: Do they recommend using a pivot?\nAnswer: unanswerable\n\nQuestion: Do they recommend using a pivot?\nAnswer: unanswerable\n\nQuestion: Do they recommend using a pivot?\nAnswer: unanswerable\n\nQuestion: Do they recommend using a pivot?\nAnswer: unanswerable\n\nQuestion:", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": "Liu (Document[12]):\"Liú is a chatbot that learns from human users and uses that knowledge to answer questions . It is a lifelong learning system that is continually learning from its users . It is a chatbot that is continually learning from its users . It is a chatbot that is continually learning from its users . It is a chatbot that is continually learning from its users . It is a chatbot that is continually learning from its users . It is a chatbot that is continually learning from its users . It is a chatbot that is continually learning from", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": "Insight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": "Reddit (Document[111]):\"Reddit is a social news aggregation, web content and discussion website . It is the site where registered users can post links or posts collecting content from around the web and discuss them . Reddit was founded in 2005 by Steve Huffman and Alexis Ohanian . The site was first known as \"Jarvus\" and later changed its name to \"Reddit\".\"\")\")\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": "Energy\n\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer: Energy\n\nQuestion: Which stock achieved the best performance?\n\nAnswer", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": "The authors are from different backgrounds: Dong is a computer scientist, Lukasiewicz is a linguist, and Nguyen is a social scientist. (BIBREF0)\n\nAnswer: The authors are from different backgrounds: Dong is a computer scientist, Lukasiewicz is a linguist, and Nguyen is a social scientist. (BIBREF0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": "SVM (section SECREF)\n\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF)\n\nAnswer: SVM (section SECREF", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": "yes\n\n\nQuestion: Do they model syntax \n\nAnswer: yes\n\nQuestion: Do they model pragmatics \nAnswer: yes\n\nQuestion: Do they model discourse \nAnswer: yes\n\nQuestion: Do they model coherence \nAnswer: yes\n\nQuestion: Do they model cohesion \nAnswer: yes\n\nQuestion: Do they model cohesion \nAnswer: yes\n\nQuestion: Do they model cohesion \nAnswer: yes\n\nQuestion: Do they model cohesion \nAnswer: yes\n\nQuestion: Do they model", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": "Conversational chatbots are a new class of conversational chatbots that are designed to be able to understand and respond to human input in a conversational manner. They are typically designed to be able to understand and respond to a wide range of topics and questions, and to be able to engage in conversation with humans.\n\nAnswer: The state of the art is described in the paper is the state of the art is the state of the art is the state of the art is the state of the art is the state of the art is the state of the art is the state of the art is the state of the", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": "a novel corpus of state-level annual speeches (Document[11]):\"We employ a novel corpus of state - level annual speeches (1973--2015) to examine the relationship between state - level ideological polarization and state - level economic performance . We use a novel corpus of state - level annual speeches (1973--2015) to examine the relationship between state - level ideological and state - level economic performance . We use a novel corpus of state - level - level - level - level - level - level - level - level -", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": "Doc2Vec (Document to Vector)\n\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector)\n\nAnswer: Doc2Vec (Document to Vector", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": "argument component (Document[100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": "yes (Document[10]):\"We use the same annotation scheme as in the previous work, but annotate the data in English . We also use the same evaluation metrics as in the previous work.\"\n\n\nQuestion: Do they report results only on English data?\n\nAnswer: yes (Document[10]:\"We use the same annotation scheme as in the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work, the previous work,", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": "unanswerable\n\n\nQuestion: What is the architecture?\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution?\n\nAnswer: unanswerable\n\nQuestion: What is the main conclusion?\n\nAnswer: unanswerable\n\nQuestion: What is the main result?\n\nAnswer: unanswerable\n\nQuestion: What is the main idea?\n\nAnswer: unanswerable\n\nQuestion: What is the main result?\n\nAnswer: unanswerable\n\nQuestion: What is the main contribution?\n\nAnswer: unanswerable\n\nQuestion: What is", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": "unanswerable\n\n\nQuestion: Do they analyze the use of slurs?\n\nAnswer: unanswerable\n\nQuestion: Do they analyze the use of slurs?\n\nAnswer: unanswerable\n\nQuestion: Do they analyze the use of slurs?\n\nAnswer: unanswerable\n\nQuestion: Do they analyze the use of slurs?\n\nAnswer: unanswerable\n\nQuestion: Do they analyze the use of slurs?\n\nAnswer: unanswerable\n\nQuestion: Do they analyze the use of slurs?\n\nAnswer: unanswerable\n\nQuestion:", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": "a state or a country (Document[111]):\"A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or a country . A node is a state or", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": "We use the same data sources as in the previous work, but we also include new sources. (Bibtex)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": "We used the New York Times Corpus, which contains all articles published in the New York Times from 1987 to 2017. We used the New York Times Corpus, which contains all articles published in the New York Times from 1987 to 2017. We used the New York Times Corpus, which contains all articles published in the New York Times from 1987 to 2017. We used the New York Times Corpus, which contains all articles published in the New York Times from 1987 to 2017.", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": "yes\n\n\nQuestion: Do they discuss the importance of interdisciplinary collaboration?\n\nAnswer: yes\n\nQuestion: Do they discuss the importance of interdisciplinary collaboration?\n\nAnswer: yes\n\nQuestion: Do they discuss the importance of interdisciplinary collaboration?\n\nAnswer: yes\n\nQuestion: Do they discuss the importance of interdisciplinary collaboration?\n\nAnswer: yes\n\nQuestion: Do they discuss the importance of interdisciplinary collaboration?\n\nAnswer: yes\n\nQuestion: Do they discuss the importance of interdisciplinary collaboration?\n\nAnswer: yes", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": "thorny\n\n\nQuestion: What are the three goals of the article?\n\nAnswer: to shed light on thorny issues, to provide best practices, to help researchers to avoid pitfalls\n\nQuestion: What is the first step in the process?\n\nAnswer: Identify a research question\n\nQuestion: What is the second step in the process?\n\nAnswer: Identify a research question\n\nQuestion: What is the third step in the process?\n\nAnswer: Identify a research question\n\nQuestion: What is the fourth step in the process?\n\nAnswer: Identify", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": "accuracy (Document[10]):\"In this section, we present the results of the evaluation of the system . We used the following metrics: accuracy, precision, recall, F1 score, and time . The accuracy metric is the ratio of the number of correct answers to the total number of answers . The precision metric is the ratio of the number of correct answers to the number of answers . The recall metric is the ratio of the number of correct answers to the total number of answers . The F1 score metric is the harmonic mean of precision and recall . The time metric is the average time of the system to answer a question", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": "yes\n\n\nQuestion: Do they use number of speeches as an indicator of preference?\n\nAnswer: no\n\nQuestion: Do they use number of speeches as an indicator of preference?\n\nAnswer: no\n\nQuestion: Do they use number of speeches as an indicator of preference?\n\nAnswer: no\n\nQuestion: Do they use number of speeches as an indicator of preference?\n\nAnswer: no\n\nQuestion: Do they use number of speeches as an indicator of preference?\n\nAnswer: no\n\nQuestion: Do they use number of speeches as an indicator of preference", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": "\"First, the annotated documents are not always available. Second, the annotated documents are not always of high quality. Third, the annotated documents are not always annotated in a way that is suitable for our task. Fourth, the annotated documents are not always annotated in a way that is suitable for our task. Fifth,,,,s,s,,s,s,s,s,s,s,s\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": "manually (Document[12]):\"We now present a set of 12 datasets, each of which is annotated with a set of semantic roles . The annotation protocols were designed to be language - agnostic, and to be language - agnostic, and to be language - agnostic, and to be language - agnostic, and to be language - agnostic, and to be language - agnostic and to be language - agnostic and to be language - agnostic and to be language - agnostic and to be language - agnostic and to be language -", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": "figurative language (e.g. \"I'm going to the store\") and non-literal language (e.g. \"I'm going to the store\") (Document[109]):\"In this work we propose a novel approach to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the problem to the", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": "Welsh, English, French, German, Italian, Japanese, Mandarin, Spanish, Russian (BIBREF1)\n\nQuestion: What is the purpose of the article?\n\nAnswer: To introduce a new dataset of 12 languages, including Welsh, English, French, German, Italian, Japanese, Mandarin, Spanish, Russian, and Welsh (BIBREF1)\n\nQuestion: What is the focus of the article?\n\nAnswer: The focus of the article is the focus of the article is the article is the article is the article is the article is the article is the article is", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}

{"pred": "They chose different pages mainly based on intuition and the nature of the datasets available for evaluation. The final selection includes Fox News, CNN, New York Times, ESPN, Cartoon Network, and Disney.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "The paper proposes attention models to infer the latent context, i.e., the series of posts that trigger an intervention.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "The article mentions F-score (F-measure) and Kappa difference as evaluation metrics.", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "The baselines were plain stacked LSTMs.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "jiant is compatible with models implemented using PyTorch and Hugging Face's Transformers library.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "The experts are experts with legal training, not real-world users.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "The article reports that shallow syntactic features offer little to no benefit to ELMo models in sentiment classification.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Four datasets were used in evaluation, including English and non-English restaurant reviews.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "The article reports a 12.26% increase in F1 score when topic information is added to sentence representation in a small-scale unbalanced dataset.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "They use both, with some assuming high-accuracy transcriptions are available and others processing the audio to determine text using ASR.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "The Carrot2 and CLUTO clustering algorithms were used.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "BERT was fine-tuned on the binary answerability task.", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "The pivot-based baselines are translation methods that use a pivot language to accomplish translation between two languages with no parallel data.", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "The EmotionLines (EmotionLines) dataset was used.", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "Several evaluation protocols are provided for each part of the database.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian-masked directional multi-head attention adjusts the weight between characters and their adjacent characters to a larger value to improve the ability of self-attention to capture local relationships.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "The article describes a method for adapting English pre-trained language models to other languages using a limited amount of computational resources. The method involves initializing the target language's word embeddings using English word embeddings and then fine-tuning the model on monolingual data from the target language. The amount of monolingual data used for fine-tuning is not specified in the article.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "The article shows that attention and alignment agree in some cases but differ in others, depending on the attention mechanism and the type of word being translated.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "They use a Recurrent Neural Network (RNN) for end-to-end speech recognition.", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "The baseline models used in the experiments are the Stanford CRF classifier and the BiLSTM-CRF model.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "This paper is unanswerable without the publication date mentioned in the article.", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "Around 500 different workers were involved in the annotation process.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "The models used in the experiment are a linear SVM, a bidirectional LSTM, and a CNN.", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "They explore BiLSTM, BiLSTM+CRF, BiLSTM+CNN, CNN, and Stanford CRF models.", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "Unsupervised term discovery (UTD) or acoustic unit discovery (AUD) methods are used to automatically discover word-like or phoneme-like units from speech.", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "They test the BERTbase model.", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "Five keyphrase extraction models were reassessed in the study.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "Yes, the encoder-decoder NMT model with pre-training offers significant improvement in BLEU scores and alleviates the problem of repeating and missing words in the translation on English-Japanese translation task. However, it cannot be trained well without pre-training.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "The MIMIC-III database was used for the study.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "The article does not provide information on the size of the dataset for each step of the hierarchy.", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "Attention captures other information beyond alignment in addition to agreeing with alignment to a certain extent.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "The baselines were bag-of-words (BOW), term frequency-inverse document frequency (TF-IDF), neural network models (TextCNN, LSTM), and a simple rule-based system.", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "They evaluate tag recommendation approaches with different numbers of recommended tags.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "The architecture of their model follows the architecture in berard2018end, but has 3 decoder layers like in pino2019harnessing. For MT, they use a Transformer base model with 3 decoder layers.", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "They used the Penn Treebank and WikiText datasets for language modeling.", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "No.", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "Prior knowledge distillation techniques cannot be utilized to produce student models with different vocabularies from the original teacher models due to the requirement of sharing the same vocabulary and output space.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "The baseline approach is the word2vec algorithm.", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "The ancient Chinese dataset is collected from the internet, specifically from ancient Chinese history records and articles written by celebrities during several dynasties.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "Unanswerable. The article focuses on the answerability of questions on Quora, not on the usefulness of answers.", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "The results demonstrate that words embeddings, style, and morality features contribute the most to detecting fake news.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "The XNLI dataset is used for classification task and Universal Dependencies for parsing task.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "The article discusses methods for building word embeddings in English, but it does not specify which languages the methods are applied to.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "No.", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "The collection of COVID-19 literature contains over 45,000 scholarly articles.", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "The proposed model is compared with TF-IDF, Naive Bayes, LSTM, and CNN baseline models.", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "The article does not provide information on the number of electrodes used in EEG sessions.", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "Macaw consists of multiple actions, each action is a module that can satisfy the information needs for different tasks, such as search algorithms, question answering, and recommendation systems.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "Yes. The indexing-based method can be applied to create other QA datasets in other domains.", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "The article does not provide information on the accents present in the corpus.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "Experiments are conducted on the SQuAD dataset.", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "They train their models on the relation classification dataset of the SemEval 2010 task 8.", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "The English Wikipedia was used for 2 times the size of the Russian corpus, which was a concatenation of the Russian Wikipedia and the full Russian National Corpus.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "The qualitative results of GM$_$KL are shown on the Text8 dataset.", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "The proposed method improves the F1 score by +0.58 for MRPC and +0.73 for QQP.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "They use the Fisher Information Matrix to indicate the expected variance of the model outputs.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "The encoder is an LSTM encoder.", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "The dataset contains natural language questions.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes, other baselines were tested.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "The new corpus consists of 53 documents.", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "The recipes are generated by the model.", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "They evaluate their resulting word embeddings using intrinsic evaluations consisting of word similarity and analogy tasks, downstream tasks from the VecEval suite, and OOV word representation analysis.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "The article mentions 15 phenotypes that are annotated, but it does not list the other 5. Therefore, it is unanswerable to list the other 10 phenotypes based on the information provided in the article.", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "Most texts range roughly from 150 to 250 tokens.", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "The textual patterns are extracted from a corpus of original and corrected sentences.", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "The article does not provide information on whether the obtained vectors are studied for numerical properties such as orthogonality.", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "The Random Kitchen Sink approach is a machine learning method used for text classification.", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "They compare to a variant where they share token embeddings and a strong sequence-to-sequence baseline.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "The results show that error detection performance is significantly improved by using artificially generated errors from both methods. The combination of both methods gave the best overall performance.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "They test their method on tasks such as Named Entity Recognition, Part-of-Speech Tagging, Text Classification, and Language Modeling.", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "Seven experts with legal training were used for annotation.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Maximum matching, Hidden Markov Model, Conditional Random Field, and Support Vector Machine have been applied to solve word segmentation in Vietnamese.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Stanford NER, spaCy NER, and a recurrent neural network model were evaluated.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "The paper uses WordNet and Freebase to evaluate the proposed method.", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "The baseline models used are not specified in the article.", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "They addressed personal attack, racism, and sexism for cyberbullying detection.", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "No, they also collected and preprocessed data from ISIS magazines in Arabic. However, their emotion analysis was done using English data only.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "An existing, annotated Twitter dataset is used for this study.", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "The Nguni languages are similar to each other.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "The IMDb dataset of movie reviews is used for sentiment analysis.", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "The classifier achieved a precision of over 90% and a recall of over 85%.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "The approach out-performs K-means, LEM, and DPEM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "The PolyResponse engine is used for restaurant search and booking in 8 languages: English, German, Spanish, Mandarin, Polish, Russian, Korean, and Serbian.", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "The datasets are from Deutsche Welle's news website.", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "No. The lexicon is built over all the data and includes the vocabulary from both the training and testing sets for each language group.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "Inferferenced: Inferferenced are evaluated in the article.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "The SBERT sentence embeddings are evaluated on seven transfer learning tasks: MR, CR, SUBJ, MPQA, MRPC, QQP, and STS-B.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "The article discusses the use of editor-assigned tags and user-generated search terms to improve the effectiveness of e-book tagging. It does not provide information on the size of the vocabulary.\n\nUnanswerable.", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Text sequences of context tweets are proposed as an additional feature for neural network models.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "Yes, the learned representations are used as input to off-the-shelf predictors to solve downstream tasks.", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "No, they generate maps reflecting the demographic, linguistic, and psycholinguistic properties of the population in the dataset.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "The ensemble+ of (r4, r6, r12) in SLC task and the ensemble+ of (r2, r5) in FLC task had the best performance. The exact performance is not mentioned in the article.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "The corpora used in the shared task correspond to the diachronic corpus pair from BIBREF0: DTA18 and DTA19. They consist of parts of the freely available diachronic corpus of German, DTA, containing texts from the 16th to the 20th century.", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "The dataset includes 10,898 articles, 17,754 tweets, and 13,757 crowdsourced question-answer pairs.", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "Three classifiers (K Nearest Neighbors, Random Forest, Support Vector Machine, and Multi-layer Perceptron) have been trained.", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "They propose extended middle context, a new context representation for CNNs in relation classification.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "Multi-granularity and multi-tasking neural architecture designs involve jointly performing fine-grained and coarse-grained tasks and leveraging multiple levels of representation.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "The CORD-19 dataset is a scholarly articles dataset about COVID-19, SARS-CoV-2, and related coronaviruses.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "The dataset contains supervisor assessment data for 4528 employees and has 26,772 sentences.", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "The article discusses the use of compound probabilistic models, specifically compound probabilistic context-free grammars (CPCFGs), for natural language processing tasks. It argues that these models can capture longer-range dependencies and improve performance compared to traditional probabilistic context-free grammars (PCFGs) and other statistical models. The article also discusses the challenges of training and inference in CPCFGs and proposes solutions using approximate inference and neural network parameterization. The results on several benchmark datasets show that CPCFGs outperform PCFGs and other models on", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "The backoff strategies involve falling back on a neutral word, a background model, or a generic word recognizer when the foreground model fails to recognize a word.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "The corpus used to learn behavior is a recorded dialogue corpus.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "BLEU-4, NIST-4, and ROUGE-4 are used for evaluation.", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "The article mentions rcsquared.net/papers/svm_text_classification.pdf, baidu.com/jingyan/doc/view/1364111.html, arxiv.org/abs/1704.04352, arxiv.org/abs/1705.08807, arxiv.org/abs/1802.05365, arxiv.org/abs/1805.08805, arxiv.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "The article uses features such as segmentation, POS tagging, and stemming for linguistic processing.", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "The semantically related words take larger values along the dimensions that align with the given concepts.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "The data is in English and German.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "The article does not mention anything about the framework automatically optimizing for hyperparameters.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "The discrepancies between the two news domains might be country-independent.", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "Experiments are performed on CoinCollector and CookingWorld Text-Based Games.", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "The two metrics proposed are F1 @ 5 and F1 @ 20.", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "Their model can detect some biases in the process of collecting or annotating datasets.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "The article mentions the possibility of driving automatic inference and enrichment by representing structured data in a hierarchical manner, and the potential use of operation-guided networks for this purpose. It also suggests further constraining the model to prevent inaccurate or contradictory descriptions.", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "The additive modification to the objective function is a term that encourages the embedding of a concept along a specific dimension based on a predefined concept group.", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "The article does not provide enough information to answer this question.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "Their document-level encoder is novel because it is based on Bert and is able to encode a document and obtain representations for its sentences.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "Their model allows attention heads to specialize and agree on the most relevant words, leading to improved interpretability compared to softmax transformers.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "The article does not provide information on the extent of the improvement in the attention mechanism's efficacy.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "The dataset consists of 22,880 users.", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "An instance is a sentence.", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "The article discusses two datasets for forecasting antisocial events in conversations: one labeled for personal attacks and the other for moderator actions.", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "The experiment uses a large-scale real-world dataset of civil case documents from mainland China. The dataset includes factual information, legal provisions, and results. It is used for training and testing the AutoJudge model.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "They calculate the root mean square error between the human-judged style labels and the model's predicted style labels.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "The improvement is an absolute improvement of 18.2%.", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "The human evaluations were conducted by a group of 50 native speakers who rated the translations on adequacy, fluency, and ranking.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "They use a joint model that integrates visual and textual features.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "The baseline was a weak NMT model without using any parallel data.", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "The article uses a set of global network properties to encode each layer of the Twitter diffusion network, including the number of strongly connected components, the size of the largest strongly connected component, the number of weakly connected components, the size of the largest weakly connected component, the diameter of the largest weakly connected component, the average clustering coefficient, the main K-core, and the structural virality.", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "The baseline models are QA model with pointer-generator network and random baseline for frequency extraction.", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "The core component for KBQA is relation detection.", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "The off-the-shelf reward learning algorithm from RL that is adapted is not explicitly stated in the article. However, it is mentioned that the objective of the algorithm is to optimize the log-likelihood of the data enriched with manipulation, and the manipulation parameters are optimized through gradient descent on the validation set.", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "The article mentions that they used BioASQ for training and testing their model.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "The manual Pyramid scores are used for evaluation and comparison with automatic evaluation metrics.", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The models estimate the contribution of each input word to every output word using the integrated gradients method, forming a contribution matrix, and then normalize the rows to obtain the word importance for the entire output sentence.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "The state of the art models are those mentioned in the article by BIBREF9 and BIBREF8.", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "The article reports significant improvements in classification performance for both low data regime and class-imbalance problems.", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "They focus on multiple choice question answering.", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "The article uses two publicly available datasets provided by Waseem et al. (Waseem, A., & Hovy, E. (2016). Hate speech detection using deep learning: An overview. ACM Transactions on Intelligent Systems and Technology, 7(2), 1-18.) and Davidson et al. (Davidson, A., et al. (2017). Hate speech detection using deep learning: An overview. ACM Transactions on Intelligent Systems and Technology, 7(2), 21-35.) for hate speech", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "They test their word importance approach on the state-of-the-art Transformer and conventional RNN models.", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "Keyphrase diversity is measured using metrics such as precision, recall, and F1 score, conditioned on the top N generated keyphrases.", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "The evaluation protocol and baseline are proposed for concept-map based multi-document summarization.", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "They compared 6-layer, 7-layer, and 9-layer sMBR models with CE initialized and sMBR models with CE initialized and fine-tuned with 1000 hours of data. They also compared 6-layer and 9-layer sMBR models with Xavier initialized and fine-tuned with 1000 hours of data.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "The article suggests that both professional and machine translation introduce artifacts that affect the performance of cross-lingual models.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "KAR is an end-to-end machine reading comprehension (MRC) model.", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Future work includes improving the sensational scorer and investigating dynamic balancing methods between RL and MLE in text generation.", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "The dataset models character's profiles using Human Level Attributes (HLAs) based on their HLA set and correlation with other characters.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "The Reuters-8 dataset has been used in this work.", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "The accuracy and area under the curve (AUC) metrics are used to evaluate the performance of the approach.", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "The authors present evidence of misclassifications in the test data, some of which they attribute to biases in the data collection and annotation process. They also mention recent studies that have shown similar findings.", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "They achieve state-of-the-art results on both SimpleQuestions and WebQuestions benchmarks.", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "The model is more reliable for correcting grammatical errors, spelling errors, and punctuation errors.", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "The authors crawled over 2M tweets from twitter to build a dataset with 262,755 ironic and 116,250 non-ironic sentences.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "Global context refers to the representation of the whole document, while local context refers to the representation of the specific topic or section within the document.", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Knowledge Base Question Answering", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They used MALLET to implement LDA and Gibbs sampling for model learning and topic discovery in ISWC and WWW publications.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "Yes.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "Women represent only 22.84% of speakers in the analyzed corpora.", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "The baseline model was to answer always 'Yes' for Yes/No questions.", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "The highest recall score was 0.7033.", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "The generated text was evaluated using BLEU, NIST, METEOR, ROUGE-L, and CIDEr metrics.", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "They used a multinomial naive Bayes classifier for their system.", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "The experiments are performed with two predetermined event categories: cyber security and death of politicians.", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "The article mentions Logistic Regression, Long Short-Term Memory networks, and a neural network model for RQE.", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "The strong baseline is the Conditional Copy (CC) model, which is the best performing model in the paper.", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "The invertibility condition is a requirement for the neural network to be invertible and have both an inverse and a Jacobian matrix.", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Logistic Regression and Multilayer Perceptron are used as target models.", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "The size of the real-world civil case dataset is not mentioned in the article.", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "The data was collected through crowdsourcing on Amazon Mechanical Turk.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "The methods used to reduce data sparsity effects include using subword units for translation, applying back-translation to generate synthetic data, and using mix-source data.", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "The article reports that the proposed model outperforms the baselines in various metrics.", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "The article provides a breakdown of how Arabic speakers use offensive language, including direct name-calling, simile and metaphor usage, indirect speech, wishing evil, and name alteration.", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The authors show that their policy solves almost half of the unseen games in the Cooking Master dataset, while existing solutions fail to solve any of them.", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "The goal is to understand the impact of gender bias on NLP performance in the news broadcast domain and the Anchor role.", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "They build a predictive model to classify dogmatic posts from non-dogmatic posts using linguistic features.", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "Yes, they released their data set of academic papers.", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "The state-of-the-art system is a message passing neural network for document representation and classification, specifically the Message Passing Neural Network (MPNN) proposed in the article.", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "They compare words of least importance with human-annotated under-translated words.", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "The model is applied to two datasets: an expanded version of the `Conversations Annotated for Toxicity' dataset and the Change My View subreddit dataset.", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "Yes. They collected Japanese-Vietnamese parallel data from TED talks.", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "The article uses the Europarl dataset for experiments.", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "Yes, they tested the proposed model on two different datasets: FBFans and CreateDebate.", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "A second order co-occurrence matrix is a similarity matrix where the similarity between two words is based on the frequency of their co-occurrence with other words.", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": "precision, recall, F1 and accuracy are reported.", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": "The authors experiment with the Language for Information Retrieval Evaluation and Analysis (LIREA) dataset, which includes English, French, and German data. However, they only report results on the English subset of the dataset.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": "They do not provide information on how annotators are matched to instances in the article.", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": "The dataset comprises 2,110 texts, 14,275 questions, and 13,939 answers.", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": "Yes, the data is de-identified.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": "Yes. They use Glove embeddings for the words in their vocabulary.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": "The standard ROUGE metric is used for evaluation.", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": "The baseline methods are Naive, mSDA, Naive CNN, and DAN.", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": "The article does not provide the absolute accuracy of the system.", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": "Word embedding techniques such as word2vec and GloVe are explored in the paper.", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": "The article uses a US dataset and an Italian dataset.", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": "The article does not provide information on how profile changes vary for influential leaders and their followers over a social movement.", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": "They show this by testing humans on a random set of questions that the model couldn't answer correctly.", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": "The macro-averaged F1 score is used in evaluation.", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": "The article does not provide enough information to answer this question.", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": "The article describes two datasets: one from Wikipedia and one from arXiv. The Wikipedia dataset consists of around 3.8 million articles, and the arXiv dataset consists of around 1.5 million articles.", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": "No, they recommend translating the premise and hypothesis independently for the Translate-Test approach.", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": "The article reports experimental results showing that LiLi outperforms several baselines in terms of predictive accuracy and strategy formulation. However, it does not explicitly state which metrics were used to evaluate these improvements.", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": "They use both computational and human-driven approaches towards text analysis.", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": "The article does not specify which dataset is used for analysis.", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": "The article does not provide information on which stock market sector achieved the best performance.", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": "They are scholars working on a research project.", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": "Multi-class SVM and Maximum Entropy Markov Model are used in experiments.", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": "Yes. The article discusses the use of word embeddings, which are a type of semantic model.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": "The paper describes the state of the art in conversational systems, focusing on natural language understanding and generation, and the use of machine learning and deep learning techniques. It also discusses challenges and future directions in the field.", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": "They use a dataset of state speeches in the UN General Assembly from 1946 to 2012.", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": "The text embedding is done using Doc2Vec (Doc2Vec is a type of Doc2Vec model, specifically Doc2Vec with the paragraph vector model).", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": "The ML methods aim to identify argument components such as claim, premises, and evidence.", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": "No, they also report results on cross-domain data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": "The set of tweets has been crawled and the news articles have been extracted from links included in these tweets.", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": "Yes, they analyze specific derogatory words and their relationships to LGBTQ labels using various techniques.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": "A node in the network approach represents a state or actor.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": "The data in the new corpus come from various sources, including user-generated content from forums and comments on news articles.", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": "They extract paragraphs containing any of the following LGBTQ terms: gay, lesbian, bisexual, transgender, LGBT, queer, homosexual, or transsexual.", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": "Yes.", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": "They shed light on thorny issues in computational text analysis.", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": "The article does not mention which evaluation metrics were used.", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": "Yes.", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": "The capabilities of the model to capture argumentation depend on the register and topic, the length of the document, and the literary devices used for expressing argumentation.", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": "The datasets were annotated by human raters following specific guidelines.", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": "The article discusses the challenges of applying argumentation theories to actual data on the web, including the presence of rhetorical devices such as narratives, rhetorical questions, and figurative language, as well as the need to filter out non-argumentative content. The article proposes a computational model for identifying argument components based on Toulmin's model, and evaluates its performance on a corpus of user-generated content. The study finds that the model is effective in identifying argument components, but that its performance varies depending on the type of data and the specific argumentation phenomena present. The article also", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": "The 12 languages covered are not explicitly stated in the article, but they are mentioned that they include a mixture of major and under-resourced languages.", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}

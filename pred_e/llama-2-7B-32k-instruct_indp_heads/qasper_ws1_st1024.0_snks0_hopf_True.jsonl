{"pred": "Fox News Corporation (B-Fox)\n\n\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer: Facebook-Fox\n\n\nQuestion: What is the name of the model they used?\n\n\nAnswer: Facebook-Fox\n\n\nQuestion: What is the name of the paper they used?\n\n\nAnswer: Facebook-Fox\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer: Facebook-Fox\n\n\nQuestion: What is the name of the model they used?\n\n\nAnswer: Facebook", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": "linear (Post) (Document)\n\n\n\n\nQuestion: What is the primary goal of the proposed models?\n\n\nAnswer: predict instructor intervention (Document)\n\n\nQuestion: What is the secondary goal of the proposed models?\n\n\nAnswer: predictor intervention (Document)\n\n\nQuestion: What is the primary goal of the proposed models?\n\n\nAnswer: predictor intervention (Document)\n\n\nQuestion: What is the secondary goal of the proposed models?\n\n\nAnswer: predictor intervention (Document)\n\n\nQuestion: What is the primary goal", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": "F-10.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": "plain stack of sentence (i) (Document)\n\n\n\n\nQuestion: What is the proposed architecture?\n\n\nAnswer: DISPLAYFORM0 DISPLAY1 DISPLAY2 DISPLAY3 DISPLAY4 DISPLAY5 DISPLAY6 DISPLAY7 DISPLAY8 DISPLAY9 DISPLAY10 DISPLAY11PLAY12PLAY13PLAY14PLAY15PLAY16PLAY17PLAY18PLAY19PLAY20PLAY21PLAY21PLAY22P", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": "unanswerable (Document)\n\n\n\nQuestion: Does jiant support any of the tasks in the GLUE benchmark?\n\n\nAnswer:yes (Document)\n\nQuestion: Does jiant support any of the tasks in the GLUE benchmark?\n\n\nAnswer:yes (Document)\n\nQuestion: Does jiant support any of the tasks in the GLUE benchmark?\n\n\nAnswer:yes (Document)\n\nQuestion: Does jiant support any of the tasks in the GLUE benchmark?\n\n\nAnswer:yes (Document)\n\nQuestion: Does jiant support any of the tasks", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": "yes (unanswerable) (Document[17]):\"The intended audience for this work is the general public, and we believe that the questions asked by the crowd are representative of the questions that a user would ask . We also believe that the answers provided by the crowd are representative of the answers that a user would expect to receive .\")\")\n\n\n\nQuestion: What is the purpose of the dataset?\n\n\nAnswer:to kickstart the development of a system that can answer questions about privacy policies (Document[1]):\"Privacy policies are legal documents that outline how a company collects,", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": "unanswerable (ELMo)\n\n\n\nAnswer:Yes\n\n\nAnswer:No\n\n\nAnswer:unanswerable\n\n\nQuestion:Does this method help in phrase chunking?\n\nAnswer:answerable (EL)\n\n\nYes\n\nAnswer:No\n\nAnswer:unanswerable\n\nQuestion:Does this method help in named entity recognition?\n\nAnswer:answerable (EL)\n\n\nYes\n\nAnswer:No\n\nAnswer:unanswerable\n\nQuestion:Does this method help in dependency parsing?\n\nAnswer:answerable (EL)\n\n", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": "Amazon reviews (Amazon) (BIBR) (B) (C) (D) (E) (F) (G) (H) (I) (J) (K) (L) (M) (N) (O) (P) (Q) (R) (S) (T) (U) (V) (W) (X) (Y) (Z) (AA) (BB) (CC) (DD) (EE) (FF) (GG) (HH) (II) (JJJ) (KKK) (LL) (", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": "1222.27% (Document)\n\n\n\nAnswer: 2.27% (Document)\n\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27% (Document)\n\nAnswer: 2.27", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": "transcribed text (Document)\n\"We use the IEMO 20007 dataset, which contains 10000 utterances of audio and their corresponding transcriptions, as the training set . We use the IEMO 2007 dataset, which contains 10000 utterances of audio and their corresponding transcriptions, as the training set . We use the IEMO 2007 dataset, which contains 10000 utterances of audio and their corresponding transcriptions, as the training set . We use the IEMO 2007 dataset", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": "CLUTOur (unanswerable)\n\n\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)\n\n\nAnswer:CLUTO (unanswerable)", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": "Bert\nBERT51\n\n\n\n\nQuestion:What is the answer to the question \"What is the answer to the question?\"?\n\n\nAnswer:T1\n\n\nWhat is the answer to the question \"What is the answer to the question?\"\n\nAnswer:T1\n\nWhat is the answer to the question \"What is the answer to the question?\"\nAnswer:T1\n\n\nWhat is the answer to the question \"What is the answer to the question?\"\nAnswer:T1\n\n\nWhat is the answer to the question \"What is the answer to the question?\"", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": "pivoting (pivot-based pivoting) pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting pivoting", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": "Emotion\nEmotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion: Emotion", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": "The protocols for each part of the database. The protocols allow researchers to investigate the performance of different methods in various scenarios (e.g. duration of the database. The protocols allow researchers to investigate the performance of different methods in various scenarios (e.g. duration, gender, age, etc.)).\n\n\n\nQuestion: what is the main goal of the database?\n\n\nAnswer: The main goal of the database is to provide a large amount of data for researchers to train and test their models.\n\n\n\nQuestion: what is the main advantage of the database?\n\n\n", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": "Gaussian- Gaussian-masked multi-directional attention is a function to map queries and keys to the representation of the input. It is similar to scaled dot-product attention, but instead of using a learnable scalar projection, it uses a learnable matrix to project the queries and keys to the same space. The output is then a learnable linear combination of the queries and keys. The learnable matrix is a learnable weight matrix, and the learnable scalar is a learnable bias. The learnable matrix is a learnable weight matrix, and the learnable scalar is a learnable bias. The learnable matrix is", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": "unanswerable (Document)\n\"We use monoligotically parallel to the parallel corpus of the target language. We use the same pre-processing and tokenization techniques as the original corpus. We use the same pre-processing and tokenization techniques as the original corpus.\"\n\n\n\nAnswer:unanswerable (Document)\n\n\"We use monolingual parallel to the parallel corpus of the target language. We use the same pre-processing and tokenization techniques as the original corpus. We use the same pre-processing and tokenization techniques as the original corpus.\"\n\n", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": "unanswered\n\n\n\n\nAnswered\n\nAnswered\n\n\nAnswered\n\n\nAnswered\n\n\nAnswered\n\n\nAnswered\n\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n\nAnswered\n", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": "RNN (Document)\n\n\n\nArticle: Introduction\nState-of-the-art automatic speech recognition (ASR) systems BIBREF0 have large model capacities and require large amounts of training data. However, annotating thousands of hours of audio data is expensive and time-consuming. Active learning (AL) BIBREF11 is a technique that can help reduce the amount of data needed to train a model by identifying the most informative samples in the unlabeled data. AL has been used in many different domains, including computer vision BIBREF2, natural language processing BIBREF", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": "Bi-LST (BIOBIO)\n\n\n\n\nQuestion: What is the baseline?\n\n\nAnswer:BiL\n\n\nQuestion: What is the baseline?\n\nAnswer:B\n\n\nQuestion: What is the baseline?\n\nAnswer:L\n\n\nQuestion: What is the baseline?\n\nAnswer:B\n\n\nQuestion: What is the baseline?\n\nAnswer:L\n\n\nQuestion: What is the baseline?\n\nAnswer:Bi\n\nQuestion: What is the baseline?\n\nAnswer:B\n\n\n", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": "208/08/2019/2019\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:The main contribution of this paper is to propose a novel natural generation model based on pre-trained BERT model, and to design a novel two-stage generation process to generate the abstracts of the documents.\n\n\n\nQuestion: What is the main issue of the previous abstractive models?\n\n\nAnswer:The main issue of the previous abstractive models is that they are not end-to-end, and the pre-", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": "50 (Document)\n\n\n\n\n\nQuestion: What is the correlation between the human evaluations and the automatic metrics?\n\n\nAnswer:0.00 (Document)\n\n\nQuestion: What is the correlation between the human evaluations and the automatic metrics?\n\n\nAnswer:0.00 (Document)\n\n\nQuestion: What is the correlation between the human evaluations and the automatic metrics?\n\n\nAnswer:0.00 (Document)\n\n\nQuestion: What is the correlation between the human evaluations and the automatic metrics?\n\n\nAnswer:0.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": "SVM (Document)\n\n\n\n\nOLID (Document)\n\nOLD (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (Document)\n\nOL (", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": "Bi- Bi-directional LSTM (Bidirectional LSTM)\n- Bi-directional LSTM (Bi-directional LSTM)\n- Bi-directional LSTM (Bi-direction LSTM)\n- Bi-al direction LSTM (Bi-direction LSTM)\n- Bi-direction LSTM (Bi-direction LSTM)\n- Bi-direction LSTM (Bi-direction LSTM)\n- Bi-direction LSTM (Bi-direction LSTM)\n- Bi-direction LSTM (Bi", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": "UTD-A-AUD (Section SEC)\n\n\n\n\nQuestion: What is the difference between UTD-AUD and UT-DT?\n\n\nAnswer:U-T-AUD (Section)\n\n\nQuestion: What is the difference between UT-AUD and UT-DT?\n\n\nAnswer:U-T-AUD (Section)\n\n\nQuestion: What is the difference between UT-AUD and UT-DT?\n\n\nAnswer:U-T-AUD (Section)\n\nQuestion: What is the difference between", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": "BERT-PN\n\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:The proposed method is a simple and effective way to improve the performance of BERT.\n\n\n\nQuestion: What is the main issue of the BERT model?\n\n\nAnswer:The BERT model is not order-invariant.\n\n\nQuestion: What is the main issue of the BERT model?\n\n\nAnswer:The BERT model is not order-invariant.\n\n\nQuestion: What is the main issue of the BERT model?\n\n\nAnswer", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": "five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase five keyphrase", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": "yes\n\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:Related Works\n\n\nQuestion:What is the main contribution of this paper?\n\nAnswer:Related Works\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:Related Works\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:Related Works\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:Related Works\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": "MIMICU-III is a freely available, deidentified, electronic health record database of 40,0000 patients admitted to the ICU at Beth Israel Deaconess Medical Center between 2001 and 2012. The database includes all of the patients' demographic, clinical, and laboratory data, including vital signs, lab results, and radiology results. The database is deidentified, and the patients' privacy is protected.\n\n\n\nQuestion:what is the purpose of the paper?\n\n\nAnswer:The purpose of the paper is to", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": "14,1410000 (Document)\n\n\n\nAnswer: 14,1000 (Document)\n\n\nAnswer: 14,1000 (Document)\n\n\nAnswer: 14,1000 (Document)\n\n\nAnswer: 14,1000 (Document)\n\n\nAnswer: 14,1000 (Document)\n\n\nAnswer: 14,1000 (Document)\n\n\nAnswer: 14,1000 (Document)\n", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": "the most relevant parts of the source word that are relevant to the target word (Document[10]):\"Attention is a mechanism that allows a neural network to focus on the most relevant parts of the input (Document[10]):\"Attention is a mechanism that allows a neural network to focus on the most relevant parts of the input\")\n\n\n\nAnswer: unanswerable\n\n\nAnswer: the most relevant parts of the input (Document[10]):\"Attention is a mechanism that allows a neural network to focus on the most relevant parts of the input\")\n\n\nAnswer: un", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": "BOW (BOW) and TF (F)\n\n\n\nAnswer:what was the purpose of the paper?\n\n\nAnswer:To propose Friends for the multi-turn dialogue task\n\n\nAnswer:what was the main contribution of the paper?\n\n\nAnswer:The proposed model achieves the best performance on the multi-turn dialogue task\n\n\nAnswer:what was the main limitation of the paper?\n\n\nAnswer:The model is not suitable for the single-turn dialogue task\n\n\nAnswer:what was the conclusion of the paper?\n\n\nAnswer:", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": "2 (i) (Document)\n\n\n\n\nQuestion: what is the dataset used for the evaluation?\n\n\nAnswer: (i) (Document)\n\nQuestion: what is the evaluation metric used?\n\n\nAnswer: (i) (Document)\n\nQuestion: what is the approach?\n\n\nAnswer: (i) (Document)\n\nQuestion: what is the result?\n\n\nAnswer: (i) (Document)\n\n\nQuestion: what is the conclusion?\n\nAnswer: (i) (Document)\n\n\nQuestion: what is the future work?", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": "baseridgearX\n\n\n\n\nQuestion:What is the name of the paper?\n\n\nAnswer:arX\n\n\nQuestion:What is the name of the author?\n\n\nAnswer:arX\n\n\nQuestion:What is the name of the article?\n\n\nAnswer:arX\n\n\nQuestion:What is the name of the journal?\n\n\nAnswer:arX\n\n\nQuestion:What is the name of the conference?\n\n\nAnswer:arX\n\n\nQuestion:What is the name of the book?\n\n\nAnswer:arX\n", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": "Penn_a_a_Pyramid_100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": "unanswerable\n\n\n\n\nQuestion: Do they use clustering?\n\n\nAnswer:yes\n\nQuestion: Do they use SVMs?\n\n\nAnswer:yes\n\nQuestion: Do they use SVMs with a kernel?\n\nAnswer:yes\n\nQuestion: Do they use SVMs with a kernel and a clustering?\n\n\nAnswer:yes\n\nQuestion: Do they use SVMs with a kernel and a clustering and a ranking?\n\n\nAnswer:no\n\nQuestion: Do they use SVMs with a kernel and a clustering and a", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": "unidentifyable (Document)\nThe student model is trained to minimize the loss of the teacher model, which is trained to minimize the loss of the student model, which is trained to minimize the loss of the teacher model, which is trained to minimize the loss of the student model, which is trained to minimize the loss of the teacher model, which is trained to minimize the loss of the student model, which is trained to minimize the loss of the teacher model, which is trained to minimize the loss of the student model, which is trained to minimize the loss of the teacher model, which", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": "word20. In this paper, we used the official word2vec embedd corpus of the Turkish movie reviews BIBREF0.\n\n\n\nQuestion:What is the main contribution of the paper?\n\n\nAnswer:We create original word embeddings for Turkish and English and use them to perform sentiment analysis on two corporaBIBREF0.\n\n\nQuestion:What is the main contribution of the paper?\n\n\nAnswer:We create original word embeddings for Turkish and English and use them to perform sentiment analysis on two corporaBREF0.\n\n\nQuestion:What is", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": "1.7K biling ancient Chinese ancient Chinese ancient books from the internet (Bibidu.com, Baidu.com, Tieba.com, etc.) (Document[10]--12)\n\n\n\nQuestion: What is the size of the dataset?\n\nAnswer:1.2M (Document[12]):\"The dataset contains 1.2M sentences of ancient Chinese and 1.2M sentences of modern Chinese . The dataset is split into 80% for training, 10% for validation and 10% for testing.\"\n", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": "unanswerable\n\n\n\nArticle: Introduction\nFrom a group of small users at the time of its inception in 2009, Quora has evolved into one of the largest and most popular Q&A sites on the Internet. The site has been able to achieve this success due to its unique and innovative approach to content moderation and review. The site has also been able to attract a large number of users due to its unique and innovative approach to content moderation and review. The site has also been able to attract a large number of users due to its unique and innovative approach to content", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": "words-based features (Document-level) (chunk)\n\n\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:chunk\n\nAnswer:", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": "XNaturalize RAMEN uses a mono-to-one transfer learning approach, we fine-tune our model on a large set of monolingual datasets. We use the following datasets for fine-tuning:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": "unanswerable\nEnglish (Document[10]):\"The models we compare are: 1) the use of n-grams (like Skip-gram) and Word2Vec, 2) the use of character n-grams (like Skip-gram) and Word2Vec, 3) the use of n-grams (like Skip-gram) and Word2Vec, 4) the use of n-grams (like Skip-gram) and Word2Vec, 5) the use of n-grams (like Skip-gram) and Word2", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": "unanswerable (unanswerable)\n\n\n\n\nAnswer:\nThe dataset is not balanced between speakers of different L1s.\n\n\nAnswer:\nThe dataset is not balanced between speakers of different L1s.\n\n\nAnswer:\nThe dataset is not balanced between speakers of different L1s.\n\n\nAnswer:\nThe dataset is not balanced between speakers of different L1s.\n\n\nAnswer:\nThe dataset is not balanced between speakers of different L1s.\n\n\nAnswer:\nThe dataset is not balanced between", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": "over 45555,0000000,00000 (Document)\n\n\n\nQuestion: How many sentences are extracted from the collection of COVID-19 literature?\n\n\nAnswer: over 360,0000 (Document)\n\n\nQuestion: How many sentences are extracted from the collection of COVID-19 literature?\n\n\nAnswer: over 360,0000 (Document)\n\n\nQuestion: How many sentences are extracted from the collection of COVID-19 literature?\n\n\nAnswer: over ", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": "ELMoSeveral (EL)\n\n\n\n\nQuestion:What is the main contribution of the paper?\n\n\nAnswer:The main contribution of the paper is to propose a neural model that combines EL and topic-based features to solve the abbreviation disambiguation problem.\n\n\n\nQuestion:What is the abbreviation disambiguation problem?\n\nAnswer:The abbreviation disambiguation problem is the problem of determining the expansion of an abbreviation.\n\n\nQuestion:What is the EL?\n\nAnswer:EL is a neural model that combines EL and topic-based features to solve the", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": "248 (Document[10]):\"The EEGG signals were recorded using a 2 × 8 electrode- nal array placed on the scalp (Fpz, Fz, Fp, Cz, Cz, Pz, Pz, Pp, Cz, and Pp) using a 1000 Hz sampling rate and a 40 dB gain amplifier . The EEG signals were filtered off-line using a band- pass filter of 0.01--30 Hz and a band- stop filter of 0.00", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": "\n\n\n\n1. Interaction\n2. Conversation\n3. User interface\n4. Retrieval\n5. Search\n6. Question and answer\n7. Natural language processing\n8. Speech processing\n9. Machine learning\n10. Data mining\n\n\nAnswer:\n\n1. Interaction\n2. Conversation\n3. User interface\n4. Retrieval\n5. Search\n6. Question and answer\n7. Natural language processing\n8. Speech processing\n9. Machine learning\n10. Data mining\n\n\nAnswer:\n\n1.", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": "yes (Wikipedia)\n\n\n\nAnswer: (Wikipedia)\n\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\nAnswer:yes\n\n", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": "unanswerable\n\n\n\n\nQuestion: how many speakers are there in the corpus?\n\n\nAnswer:answerable\n\nQuestion: what is the largest number of speakers in the corpus?\n\n\nAnswer:answerable\nQuestion: what is the smallest number of speakers in the corpus?\n\n\nAnswer:unanswerable\nQuestion: what is the average number of speakers in the corpus?\n\n\nAnswer:answerable\nQuestion: what is the median number of speakers in the corpus?\n\n\nAnswer:answerable\nQuestion: what is the", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": "SQuora question generation from reading comprehension (Document)\n\n\n\n\nQuestion:What is the task of the paper?\n\nAnswer:Question generation\n\n\nQuestion:What is the main contribution of the paper?\nAnswer:structure combines unstructured text (Document)\n\n\nQuestion:What is the main task of the paper?\nAnswer:Question generation\n\n\nQuestion:What is the main contribution of the paper?\nAnswer:structure combines unstructured text (Document)\n\n\nQuestion:What is the paper about?\n\nAnswer:Question generation\n\nQuestion", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": "Semant 8,000000\n\n\n\n\nQuestion: What is the difference between CNN and RNN?\n\nAnswer:CNNs are shallow and RNNs are deep\n\n\nQuestion: What is the difference between CNN and RNN?\n\nAnswer:CNNs are shallow and RNNs are deep\n\n\nQuestion: What is the difference between CNN and RNN?\n\nAnswer:CNNs are shallow and RNNs are deep\n\n\nQuestion: What is the difference between CNN and RNN?\n\nAnswer:CNNs", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": "\n English Wikipedia: 10.5 billion tokens (Bibid: 1.5 billion)\n\n\n\nAnswer: 1.5 billion (ibid: 0.5 billion)\n\n\nAnswer: 0.5 billion (ibid: 1.5 billion)\n\n\nAnswer: 1.5 billion (ibid: 0.5 billion)\n\n\nAnswer: 0.5 billion (ibid: 1.5 billion)\n\n\nAnswer: 1.5 billion (ibid: 0.5 billion)\n\n\nAnswer", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": "unanswerable\n\n\n\n\"We train our proposed model GM_KL on the Text8 dataset and obtain the following results.\n\n\nThe model is able to capture the sense of the word and is able to capture the context of the word.\n\n\nThe model is able to capture the sense of the word and is able to capture the context of the word.\n\n\nThe model is able to capture the sense of the word and is able to capture the context of the word.\n\n\nThe model is able to capture the sense of the word and is able to capture the context of the word", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": "significant performance boost (unanswerable)\n\n\n\n\nQuestion: What is the main idea of the paper?\n\n\nAnswer: alleviate the severe data imbalance problem (unanswerable)\n\n\nQuestion: What is the main idea of the paper?\n\n\nAnswer: alleviate the severe data imbalance problem (unanswerable)\n\n\nQuestion: What is the main idea of the paper?\n\n\nAnswer: alleviate the severe data imbalance problem (unanswerable)\n\n\nQuestion: What is the main idea of the paper?\n\n", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": "\n\n\nThe gradients are obtained by minimizing the negative log-likelihood loss on the test set, INLINEFORM0\n\n\n\nAnswer:\n\nAnswerable\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": "LSTMost of the main results in Table TABREF17 are based on the baseline system, which is a character-based encoder with an embedding layer of size 100 and a character-based LSTM layer of size 100. The LSTM layer is initialized with a random Gaussian distribution with a mean of 0 and a standard deviation of 0.5. The character-based encoder is initialized with a random distribution of embeddings of size 100. The embeddings are initialized with a random distribution of embeddings of size 100", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": "unanswerable (Document)\n\n\n\n\nQuestion: What is the size of the dataset?\n\n\nAnswer:unanswerable (Document)\n\n\nQuestion: What is the size of the dataset?\n\nAnswer:unanswerable (Document)\n\nQuestion: What is the size of the dataset?\n\n\nAnswer:unanswerable (Document)\n\nQuestion: What is the size of the dataset?\n\nAnswer:unanswerable (Document)\n\n\nQuestion: What is the size of the dataset?\n\n\nAnswer:unanswerable (Document)\n\nQuestion:", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": "Yes (BERT)\n\n\n\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\n", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": "53 (Document)\n\n\n\n\nQuestion: How many sentences are in the new corpus?\n\n\nAnswer: 8,2750 (Sentence)\n\n\nQuestion: How many entities are annotated in the new corpus?\n\n\nAnswer: 1,000 (Entity)\n\n\nQuestion: How many relations are annotated in the new corpus?\n\n\nAnswer: 1,000 (Relation)\n\n\nQuestion: How many relations are annotated in the new corpus?\n\n\nAnswer: 1,", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": "Food.com (tab:sample:sample:sample:sample)\n\n\n\nQuestion: What is the dataset used for training?\n\n\nAnswer:. (tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab:tab", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": "Intrough they evaluate their resulting IV using the VecEval suite of tasks BIBIBREF10, BIBREF11, BIBREF12, BIBREF13, BIBREF14, BIBREF15, BIBREF16, BIBREF17, BIBREF18, BIBREF19, BIBREF20, BIBREF21, BIBREF22, BIBREF23, BIBREF24, BIBREF25, BIBREF26, BIBREF27, BIBREF", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": "unanswerable\n\n\n\nQuestion: What is the number of patients in the dataset?\n\n\nAnswer:unanswerable\n\nQuestion: What is the number of notes in the dataset?\n\n\nAnswer:unanswerable\n\nQuestion: What is the number of unique tokens in the dataset?\n\n\nAnswer:answerable\n\nQuestion: What is the number of unique tokens in the dataset?\n\n\nAnswer:answerable\n\nQuestion: What is the number of unique tokens in the dataset?\n\nAnswer:answerable\n\nQuestion: What is the number of unique tokens in the dataset", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": "150\n\n\n\n\n\nQuestion: How many languages are represented in the dataset?\n\nAnswer:15\n\n\nQuestion: How many texts are there in the dataset?\n\nAnswer:1,8688\n\n\nQuestion: How many tokens are there in the dataset?\n\nAnswer:384,560\n\n\nQuestion: How many topics are there in the dataset?\n\nAnswer:148\n\n\nQuestion: How many authors are there in the dataset?\n\nAnswer:1,868\n\n\nQuestion: How many documents", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": "textual patterns learned from an annotated corrections (BIBREF1)\n\n\n\nQuestion: What is the purpose of the error generation system?\n\nAnswer:to generate artificially annotated data (RB)\n\n\nQuestion: What is the main contribution of the paper?\n\nAnswer:a framework for generating artificially annotated data (P)\n\n\nQuestion: What is the main method used for generating artificially annotated data?\n\n\nAnswer:a framework for generating artificially annotated data (P)\n\nQuestion: What is the purpose of the error generation system?\n", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": "unanswerable\n\n\n\n\nThe concatenation of the concatenated vectors is done by taking the dot product of the vectors, and the resulting matrix is called the semantic embedding of the word. The semantic embedding of a word is a vector in the semantic space, and the semantic space is a high-dimensional space. The semantic space is a space where the vectors of the words that have the same meaning are close to each other. The semantic space is a space where the vectors of the words that have the same meaning are close to each other. The semantic space is a space where the vectors of the words that have the same meaning", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": "RKS approach proposed in the articles for NLP tasks [29, 230, 231, 232, 233, 24, 25, 26, 27, 28, 29, 30, 31, 32, 333, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 444, 45, 46", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": "The baseline (Inanan) (Inan)\n\n\n\nQuestion: What is the best strategy for adding pre-trained language models to a sequence-to-sequence model?\n\n\nAnswer: ELMo embeddings (ELMo embeddings)\n\n\nQuestion: What is the best strategy for adding pre-trained language models to a sequence-to-sequence model?\n\n\nAnswer: ELMo embeddings (ELMo embeddings)\n\n\nQuestion: What is the best strategy for adding pre-trained language models to a sequence-to-sequence model?", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": "The results show that error generation models provide significant improvements in error detection performance. (Document)\n\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer: two alternative AEG methods, a pattern-based approach and a machine translation-based approach, and show that both of them provide significant improvements in error detection performance. (Document)\n\n\nQuestion: What is the main goal of this paper?\n\nAnswer: to investigate two alternative AEG methods, a pattern-based approach and a machine translation-based approach, and show that both of them provide significant improvements in error detection performance. (Document", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": "unanswerable (Table 1)\n\n\n\nQuestion: How many hashtags are used in the dataset?\n\n\nAnswer:unanswerable (Table 1)\n\nQuestion: How many words are in the vocabulary?\n\n\nAnswer:unanswerable (Table 1)\n\nQuestion: How many characters are in the input sequences?\n\n\nAnswer:unanswerable (Table 1)\n\nQuestion: How many characters are in the output sequences?\n\n\nAnswer:unanswerable (Table 1)\n\nQuestion: How many characters are in the", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": "seven experper domain experts (BIBR)\n\n\n\n\n\nQuestion:What is the purpose of the PrivacyQA dataset?\n\nAnswer:to kickstart the development of question answering systems for the privacy domain (B)\n\n\n\nQuestion:What is the size of the PrivacyQA dataset?\nAnswer:1700000000000000000000000000000000000000000000000000000", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": "Maximum approaches, Conditional guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidelines, lexical guidel", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": "Stanford named entity recognition (NER) is a task that aims to identify the named entities in a given text. The task is often referred to as Named Entity Recognition (NER) or named Entity Recognition (NER).\n\n\n\nQuestion: what is the main contribution of the paper?\n\n\nAnswer:the silver standard standard test set for the Armenian language\n\n\nQuestion: what is the main contribution of the paper?\n\n\nAnswer:the silver standard test set for the Armenian language\n\n\nQuestion: what is the main contribution of the paper?\n\n\nAnswer:", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": "WN/p>\n\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:p>\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:p>\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:p>\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:p>\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:p>\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:p", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": "Last State-of-the-the-art RNN (LST-RNN) (BIBREF1)\n\n\n\nAnswer: Last-of-the-art RNN (LST-RNN)\n\n\n\nAnswer: Last-of-the-art RNN (LST-RNN)\n\n\n\nAnswer: Last-of-the-art RNN (LST-RNN)\n\n\nAnswer: Last-of-the-art RNN (LST-RNN)\n\n\nAnswer: Last-of-the-art RNN (L", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": "personal (Former) personal attacks (Bul) personal attacks (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul) cyberbullying (Bul", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": "yes\n\n\n\n\n\nQuestion: What is the main topic of the article?\n\n\nAnswer: ISISIS propaganda\n\n\nQuestion: What is the main topic of the article?\n\n\nAnswer:ISIS propaganda\n\n\nQuestion: What is the main topic of the article?\n\n\nAnswer:ISIS propaganda\n\n\nQuestion: What is the main topic of the article?\n\n\n\nAnswer:ISIS propaganda\n\n\nQuestion: What is the main topic of the article?\n\n\nAnswer:ISIS propaganda\n\n\nQuestion: What is", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": "an annotated Twitter dataset that was constructed based on a hierarchical schema of depression-related symptoms and behaviors BIBREF10\n\n\n\nAnswer:\n\nThe dataset used in this study is an annotated Twitter dataset that was constructed based on a hierarchical schema of depression-related symptoms and behaviors BIBREF10.\n\n\n\nAnswer:\n\nThe dataset used in this study is an annotated Twitter dataset that was constructed on a hierarchical schema of depression-related symptoms and behaviors BIBREF10.\n\n\nAnswer:\n\n", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": "unanswerable\n\n\n\nThe Nguni language classification of short pieces of text is a challenging task. The problem is further complicated in the South African context where the 11 official languages are similar to each other.\n\n\n\nQuestion: What is the purpose of the paper?\n\nAnswer:unanswerable\n\nThe paper presents a hierarchical naive Bayes and lexicon classifier for the classification of short pieces of text.\n\n\nQuestion: What is the focus of the paper?\n\nAnswer:unanswerable\n\nThe paper focuses on the classification of short pieces of text", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": "IMDb (BIBIBM) (BIBM)\n\n\n\nArticle:\n\nIntroduction\n\nThe sentiment of a text is the overall attitude of the author towards the subject of the text. It is a subjective judgment of the polarity of the author's attitude towards the subject of the text. The sentiment of a text is a subjective judgment of the polarity of the author's attitude towards the subject of the text. The sentiment of a text is a subjective judgment of the polarity of the author's attitude towards the subject of the text. The sentiment of a text is a subject", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": "89999.6% (Document)\n\n\n\n\nQuestion: What was the accuracy of the system?\n\n\nAnswer:89.6% (Document)\n\n\nQuestion: What was the accuracy of the system?\n\n\nAnswer:89.6% (Document)\n\n\nQuestion: What was the accuracy of the system?\n\n\nAnswer:89.6% (Document)\n\n\nQuestion: What was the accuracy of the system?\n\n\nAnswer:89.6% (Document)\n\n\nQuestion: What was the accuracy of", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": "K-meanswers the state-of-the-art approaches LEM (LEM)\n\n\n\n\nQuestion: What is the main limitation of the current approach?\n\n\nAnswer:-the assumption that all the events are described in the text are not suitable\n\n\n-the assumption that all the events are described in the text are not suitable\n\n-the assumption that all the events are described in the text are not suitable\n-the assumption that all the events are described in the text are not suitable\n-the assumption that all the events are described in the text are not suitable\n-the assumption", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": "English (Edinburgh) German (Berlin) Spanish (Espa) Mandarin (Chin) Polish (Pln) Russian (Rus) Spanish (Spa) and (Tai)\n\n\n\nArticle: Introduction\n\nThe current paper presents a demo system for a restaurant search and booking system based on the Polyglot Response (PolyRep) engine. The PolyRep engine is a retrieval system that uses a large corpus of text and images to generate responses to user queries. The system is designed to be used in a restaurant setting, where users can ask the system for information about the", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": "Table TABREF30\n\n\n\n\nQuestion: What is the number of languages in the dataset?\n\n\nAnswer:ABREF30\n\n\nQuestion: What is the number of documents in the dataset?\n\n\nAnswer:ABREF30\n\n\nQuestion: What is the number of clusters in the dataset?\n\n\nAnswer:ABREF30\n\n\nQuestion: What is the number of features in the dataset?\n\n\nAnswer:ABREF30\n\n\nQuestion: What is the number of clusters in the dataset?\n\n\nAnswer:ABREF30", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": "unanswerable\n\n\n\nThe lexicon is built over all the languages and is used to predict the specific language.\n\n\n\nQuestion: What is the difference between the NB and the NB+Lex?\n\n\nAnswer:answerable\n\nThe NB is a naive Bayes classifier that predicts the language. The NB+Lex is a naive Bayes classifier that predicts the language and uses a lexicon to predict the specific language.\n\n\nQuestion: What is the difference between the NB and the NB+NB?\n\n\nAnswer:", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": "average Glove cosine cosine GloVe\n\n\n\n\nQuestion:What is the default pooling strategy for SBERT?\n\n\nAnswer:max\n\n\nQuestion:What is the difference between SBERT and SG?\n\n\nAnswer:S\n\n\nQuestion:What is the difference between SG and S?\n\n\nAnswer:S\n\n\nQuestion:What is the difference between SG and S?\n\n\nAnswer:S\n\n\nQuestion:What is the difference between SG and S?\n\nAnswer:S\n\n\nQuestion:What is the", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": "SentEvaluable.\n\n\n\n\nQuestion:What is the correlation between the STANS and the STANS?\n\n\nAnswer:unanswerable\n\nQuestion:What is the correlation between the STANS and the STANS?\n\n\nAnswer:unanswerable\nQuestion:What is the correlation between the STANS and the STANS?\n\n\nAnswer:unanswerable\nQuestion:What is the correlation between the STANS and the STANS?\n\n\nAnswer:unanswerable\nQuestion:What is the correlation between the STANS and the", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": "30.1 million (Document)\n\n\n\n\nQuestion: how many tags are there?\n\n\nAnswer:4.1 million (Document)\n\n\nQuestion: how many tags are there?\n\nAnswer:4.1 million (Document)\n\n\nQuestion: how many tags are there?\n\nAnswer:4.1 million (Document)\n\n\nQuestion: how many tags are there?\n\nAnswer:4.1 million (Document)\n\n\nQuestion: how many tags are there?\n\nAnswer:4.1 million (Document)\n\nQuestion: how many", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": "Context of context of context\n\n\n\n\nQuestion: What is the main conclusion of the article?\n\nAnswer: Contextualized models are more accurate than traditional models\n\n\n\nQuestion: What is the main point of the article?\n\nAnswer: Contextualized models are more accurate than traditional models\n\n\nQuestion: What is the main point of the article?\n\nAnswer: Contextualized models are more accurate than traditional models\n\n\nQuestion: What is the main point of the article?\n\nAnswer: Contextualized models are more accurate than traditional models\n\n\nQuestion: What is the", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": "yes\n\n\n\n\nQuestion: What is the main motivation for the models?\n\nAnswer: to capture richer semantic information from the tweets (Document)\n\n\nQuestion: What is the main motivation for the models?\nAnswer: to capture richer semantic information from the tweets (Document)\n\n\nQuestion: What is the main motivation for the models?\nAnswer: to capture richer semantic information from the tweets (Document)\n\n\nQuestion: What is the main motivation for the models?\nAnswer: to capture richer semantic information from the tweets (Document)", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": "yes (unanswerable)\n\n\n\nQuestion: What is the purpose of the paper?\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main contribution of the paper?\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main methodology used in the paper?\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main result of the paper?\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main conclusion of the paper?\n\nAnswer: (unanswerable)\n\n\nQuestion:", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": "3rd19 (unanswerable)\n\n\n\nQuestion: What is the best performing model among the other participants?\n\n\nAnswer:3rd (unanswerable)\n\nQuestion: What is the best performing model among the other participants?\n\n\nAnswer:3rd (unanswerable)\n\nQuestion: What is the best performing model among the other participants?\n\n\nAnswer:3rd (unanswerable)\n\nQuestion: What is the best performing model among the other participants?\n\n\nAnswer:3rd (unanswerable)\n\nQuestion: What is the best", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": "DTA1818 and DTA19 (Document)\n\n\n\nArticle:Introduction\nNatural languages evolve and words change their meaning over time. The study of lexical semantic change is a sub-field of historical linguistics. The study of lexical semantic change is concerned with the study of the meaning of words and how their meaning changes over time. The study of lexical semantic change is concerned with the study of the meaning of words and how their meaning changes over time. The study of lexical semantic change is concerned with the study of the meaning of words and how their meaning changes over time.", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": "10.0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": "K Nearest Nearest Neighest Neighbor (KNN) (Document[10]):\"K Nearest Neighest Neighbor (KNN) is a simple and effective algorithm for classification, regression, and other machine learning tasks . It is a probabilistic modeling approach based on the hypothesis that similar objects are more likely to be similar to each other than objects that are dissimilar . It is a non-parametric method, as it does not require any prior assumptions about the distribution of the data . It is a very popular and powerful method for classification and regression, and is often used as a", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": "Extended to CNNs (1) We propose extended middle middle context, a new context representation for CNNs (2) We present connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connectionist connection", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": "multi-\n\n\n\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-\n\n-", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": "a collection of over 4550,000000 scholarly articles, including over 35,00000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses that have been published since November 2019 (Document[2]).)\n\n\n\nQuestion: What is the purpose of the CORD-19 dataset?\n\n\nAnswer: to collect and organize scholarly articles about COVID-19, SARS-CoV-2, and related coronaviruses that have", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": "2600000000 (Document)\n\n\n\n\nQuestion: What is the size of the dataset?\n\n\nAnswer: 2000 (Document)\n\n\nQuestion: What is the size of the dataset?\n\n\nAnswer: 2000 (Document)\n\n\nQuestion: What is the size of the dataset?\n\n\nAnswer: 2000 (Document)\n\n\nQuestion: What is the size of the dataset?\n\n\nAnswer: 2000 (Document)\n\n\nQuestion: What is the", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": "BIBBIBM (Bidirectional Markov Model)\n\n\n\n\nQuestion:what is the state of the art method?\n\n\nAnswer:Bidirectional Markov Model\n\n\nQuestion:what is the state of the art method?\n\n\nAnswer:Bidirectional Markov Model\n\n\nQuestion:what is the state of the art method?\n\n\nAnswer:Bidirectional Markov Model\n\n\nQuestion:what is the state of the art method?\n\n\nAnswer:Bidirectional Markov Model\n\n\nQuestion:what is the", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": "The neutral word recognition of the sentiment sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment of the sentiment", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": "DSTTeach corpus of recorded dialogues between real users and an SDR system BIBIBL: DST-2013 (BIBL: DST-2013) is a corpus of 2013 dialogues between real users and an SDR system. The corpus was collected in the context of the DST-2013 project, which aimed to develop a new generation of SDR systems. The corpus is available at the following URL: http://www.sdr.t.u-tokyo.ac.jp/dst-2", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": "BLEUsed the evaluation metrics used for evaluation are BLEUU (B) (L) (E) (U) (B) (L) (E) (U) (R) (O) (G) (E) (D) (T) (A) (M) (E) (N) (S) (T) (A) (M) (E) (N) (S) (T) (A) (M) (E) (N) (S) (T) (A) (M) (E) (N) (S) (T", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": "AutoJud of the state-of-the-art models (BIB)\n\n\n\n\nQuestion:what is the purpose of the paper?\n\n\nAnswer:The purpose of the paper is to explore the task of predicting judicial decisions (B)\n\n\n\nQuestion:what is the main contribution of the paper?\n\n\nAnswer:The main contribution of the paper is to propose a novel framework for the task of predicting judicial decisions (B)\n\n\n\nQuestion:what is the task of the paper?\n\nAnswer:The task of the paper is to explore", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": "surface morphological features (e.g.g. morphology (e.g. morphology), POS, POS, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, POS tags, P", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": "the modified objective approach ( EQ)\n\n\n\n\nQuestion: What is the main goal of the proposed method?\n\n\nAnswer: to improve the interpretability of the word embeddings (Q)\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: a novel method for improving the interpretability of word embeddings (Q)\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: a novel method for improving the interpretability of word embeddings (Q)\n\n\nQuestion: What is the main contribution of the", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": "English (INLINE)\n\n\n\n\n\nQuestion: What is the domain of the data?\n\n\nAnswer: (IN)\n\n\nQuestion: What is the size of the data?\n\n\nAnswer: (IN)\n\n\nQuestion: What is the format of the data?\n\n\nAnswer: (IN)\n\n\nQuestion: What is the source of the data?\n\n\nAnswer: (IN)\n\n\nQuestion: What is the target of the data?\n\n\nAnswer: (IN)\n\n\nQuestion: What is the task of the data?\n\n", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": "unanswerable\n\n\n\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\n\nAnswer:yes\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\n\nAnswer:yes\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\n\nAnswer:yes\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\n\nAnswer:yes\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\n\nAnswer:yes\n\nQuestion: Does their framework automatically optimize for hyperparameters?\n\n\nAnswer:yes\n\nQuestion: Does their framework automatically", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": "discrecentific\n\n\n\n\n\nQuestion:What is the most discriminative feature of the two news domains?\n\n\nAnswer:different\n\n\nQuestion: What is the most discriminative feature of the two news domains?\n\n\nAnswer:different\n\n\nQuestion: What is the most discriminative feature of the two news domains?\n\n\nAnswer:different\n\n\nQuestion: What is the most discriminative feature of the two news domains?\n\n\nAnswer:different\n\n\nQuestion: What is the most discriminative feature of the two news", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": "Coin the family of text-based games called Coin-text-based games (BIBBIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (BIBREF) Text-based games (", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": "F1. F1-INLINEFORM0\n2-INFORM0\n\n\n\nQuestion: What is the purpose of the paper?\n\n\nAnswer:1-INFORM0\n2-INFORM0\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:1-INFORM0\n2-INFORM0\n\n\nQuestion: What is the main limitation of the paper?\n\n\nAnswer:1-INFORM0\n2-INFORM0\n\nQuestion: What is the main conclusion of the paper?\n\n\nAnswer:1-INFORM", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": "biasespect of context of context of tweets\n\n\n\n\n\nQuestion: What is the main problem with the current state of the art?\n\n\nAnswer:hat the pre-trained BERT model is not able to capture the context of tweets\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:a transfer of context of tweets\n\n\nQuestion: What is the main problem with the current state of the art?\n\n\nAnswer:hat the pre-trained BERT model is not able to capture the context of tweets\n\n\nQuestion", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": "unanswered\nWe would also like to draw attention to the number of parameters used by those architectures. We note that our model relies on a lower number of parameters (14 millions) compared to all baselines (ranging from 23 to 45 millions). This outlines the effectiveness of our model in terms of computational cost.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": "\n\n\n\nThe cost function J(x) = ∑ i = 1 N ∑ j = 1 ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ∂ ", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": "unanswerable (they report results only on English data)\n\n\n\n\nQuestion: What is the number of news articles in the dataset?\n\n\nAnswer:unanswerable (they do not report the number of news articles in the dataset)\n\n\nQuestion: What is the number of entity entities in the dataset?\n\n\nAnswer:unanswerable (they do not report the number of entities in the dataset)\n\n\nQuestion: What is the number of relations in the dataset?\n\n\nAnswer:unanswerable (they do not report the number of relations in the dataset)\n\n\n", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": "novel document-level document-level encoder\n\n\n\n\nQuestion: What is the difference between the document-level encoder and the sentence-level encoder?\n\n\n\nAnswer:sentence-level enc\n\n\nQuestion: What is the difference between the document-level encoder and the sentence-level encoder?\n\n\n\nAnswer:sentence-level enc\n\nQuestion: What is the difference between the document-level encoder and the sentence-level encoder?\n\n\nAnswer:sentence-level enc\n\nQuestion: What is the difference between the document-level enc", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": "unanswered by gradient-entropy of gradient-based optimization, side-stepping the adversor-side optimization, and the ability to learn different sparsity patterns for each head.\n\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable\n\n\nAnswer:unanswerable", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": "0.57373 (Document)\n\n\n\n\nQuestion: What is the main advantage of using a morpheme?\n\n\nAnswer:a more efficient way of representing the meaning of a word (Document)\n\n\nQuestion: What is the main advantage of using a morpheme?\n\n\nAnswer:a more efficient way of representing the meaning of a word (Document)\n\n\nQuestion: What is the main advantage of using a morpheme?\n\n\nAnswer:a more efficient way of representing the meaning of a word (Document)\n\n\nQuestion: What is the main advantage", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": "22222,88880\n\n\n\n\nAnswer:2,8880\n\n\nAnswer:2,880\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\nAnswer:2,80\n\n\n", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": "sentence (unanswerable)\n\n\n\n\nQuestion: What is the difference between inter-annotator and domain-annotor-or-crowd?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the difference between inter-annotator and domain-annot-or-crowd?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the difference between inter-annotator and domain-annot-or-crowd?\n\n\nAnswer:unanswerable\n\nQuestion: What is the difference between inter-annotator and domain-annot-or-", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": "Wikipedia\n\n\n\n\n\n\nQuestion:\nWhat is the goal of the work?\n\n\nAnswer:\n\nto forecasting the future\n\n\nQuestion:\n\nWhat is the main challenge in the work?\n\nAnswer:\n\nthe dynamic horizon\n\n\nQuestion:\n\nWhat is the main contribution of the work?\n\nAnswer:\n\na model that can forecast the future\n\nQuestion:\n\nWhat is the main limitation of the work?\n\nAnswer:\n\nthe model is not able to forecast the future\n\nQuestion:\n\nWhat is the main", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": "divor divorce cases (Document)\n\n\n\n\nQuestion: what is the purpose of the proposed model?\n\n\nAnswer:The proposed model is a novel neural network architecture that can be used for a variety of tasks, including image classification, object detection, and segmentation. It is based on the idea of using a convolutionalayer followed by a max-pooling layer, and then a fully connected layer. The convolutionalayer is used to extract features from the input data, and the max-pooling layer is used to reduce the number of features. The fully connected layer is used to classify the data.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": "unanswerable\nThe model's very own latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence's very latentence'", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": "18.2% (Document)\n\n\n\n\nQuestion: What is the best performing state-of-the-art model?\n\n\nAnswer:PointerNetAttention (Document)\n\n\nQuestion: What is the best performing state-of-the-art model?\n\n\nAnswer:PointerNetAttention (Document)\n\n\nQuestion: What is the best performing state-of-the-art model?\n\n\nAnswer:PointerAttention (Document)\n\nQuestion: What is the best performing state-of-the-art model?\n\n\nAnswer:PointerAtt", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": "unanswered in Table TABREFREFREF0\n\n\n\n\nQuestion: What is the main conclusion of the paper?\n\n\nAnswer:The morphological paper is about the use of morphological models in the field of machine learning.\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:The paper is about the use of morphological models in the field of machine learning.\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:The paper is about the use of morphological models in the field of machine learning.\n\n\n", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": "Joint a joint model that combines visual features of the visual and textual features of the document\n\n\n\n\nQuestion: What is the purpose of the paper?\n\n\nAnswer:The purpose of the paper is to propose a new model that combines visual and textual features of the document\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:The main contribution of the paper is to propose a new model that combines visual and textual features of the document\n\n\nQuestion: What is the task of the paper?\n\nAnswer:The task of the paper is", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": "Jaizhan\nWe have evaluated an extensive set of MTok\n\n\n\nQuestion:what was the best model?\n\n\nAnswer:Jaiz\n\n\nQuestion:what was the second best model?\n\n\nAnswer:Jaiz\n\nQuestion:what was the third best model?\n\n\nAnswer:Jaiz\nQuestion:what was the fourth best model?\n\n\nAnswer:Jaiz\nQuestion:what was the fifth best model?\n\n\nAnswer:Jaiz\nQuestion:what was the sixth best model?\n\n\nAnswer:Jaiz\n", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": "LW, U, D, and R, which correspond to the breadthreshipth of the article\n\n\n\n\nQuestion: What is the difference between the single-layer and multi-layer networks?\n\n\nAnswer:The difference between the single-layer and multi-layer networks is that the single-layer networks are composed of a single layer of nodes, while the multi-layer networks are composed of multiple layers of nodes.\n\n\n\nQuestion: What is the difference between the single-layer and multi-layer networks?\n\n\nAnswer:The difference between the single-layer and multi-layer", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": "ELMoSentire-of-none-of-none-of-of-none-of-of-none-of-of-none-of-of-none-of-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-of-none-", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": "HRank relation extraction (HR)\n\n\n\n\nQuestion:What is the main focus of this paper?\n\n\nAnswer:KB relation (HR)\n\n\nQuestion:What is the main focus of this paper?\n\n\nAnswer:KB relation (HR)\n\n\nQuestion:What is the main focus of this paper?\n\n\nAnswer:KB relation (HR)\n\n\nQuestion:What is the main focus of this paper?\n\n\nAnswer:KB relation (HR)\n\n\nQuestion:What is the main focus of this paper?\n\n\nAnswer:KB relation", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": "BIBRewnAdaptive an off-the-shelf Reward Learning for Data Augni ng (RLDAN) BIBREF0, BIBREF1, BIBREF2, BIBREF3, BIBREF4, BIBREF5, BIBREF6, BIBREF7, BIBREF8, BIBREF9, BIBRE10, BIBRE11, BIBRE12, BIBRE13, BIBRE14, BIBRE15, BIBRE16, BIBRE17,", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": "BioASQ: BioASQ\n\n\n\n\nQuestion: What is the BioASQ dataset?\n\n\nAnswer:BioASQ\n\n\nQuestion: What is the BioASQ dataset?\n\n\nAnswer:BioASQ\n\n\nQuestion: What is the BioASQ dataset?\n\n\nAnswer:BioASQ\n\n\nQuestion: What is the BioASQ dataset?\n\n\nAnswer:BioASQ\n\n\nQuestion: What is the BioASQ dataset?\n\n\nAnswer:BioASQ\n\n\nQuestion: What is the Bio", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": "TACMost of the human annotators annotated the summaries and the gold summaries and calculated the similarity between them. The human annotators were asked to evaluate the summaries based on the following criteria:\n\n\n\nAnswer:\n\n1.\tThe summary is a good summary of the original document.\n2.\tThe summary is a bad summary of the original document.\n3.\tThe summary is a good summary of the original document but the original document is a bad one.\n4.\tThe summary is a bad summary of the original document but the original document is a good one.\n5", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": "The contribution of each word in the input sequence (Bibid.\n\n\n\nAnswer: unanswer: unanswerable\n\n\nQuestion: What is the difference between the attention and the integrated method?\n\n\nAnswer: the attention method is a black-box method, while the integrated method is a white-box method (Bib\n\n\n\n: unanswer: unanswerable\n\nQuestion: What is the difference between the attention and the integrated method?\n\n\nAnswer: the attention method is a black-box method, while the integrated method is a white-box method (Bib\n\n", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": "BIBREF9\n\n\n\n\n\nQuestion: What is the proposed approach?\n\nAnswer:The proposed approach is a deep learning model that uses a convolutional neural network to learn the features of the input data and then uses a softmax layer to output the probability of the class.\n\n\n\nAnswer:The proposed approach is a deep learning model that uses a convolutional neural network to learn the features of the input and then uses a softmax layer to output the probability of the class.\n\n\n\nQuestion: What is the baseline?\n\nAnswer:The baseline is a simple logistic regression", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": "significant improvement (Document)\n\n\n\n\nAnswer: significant improvement (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\nsignificant (Document)\n\n\n", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": "multiple choice question answering (MCQA) (Document)\n\n\n\n\nQuestion: What is the main focus of the paper?\n\n\nAnswer: probing state-of-the-art multiple-choice question-answering (QA) (Document)\n\n\n\nQuestion: What is the main focus of the paper?\n\n\nAnswer: probing state-of-the-art multiple-question-answering (QA) (Document)\n\n\n\nQuestion: What is the main focus of the paper?\n\n\nAnswer: probing state-of-the-art multiple", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": "Waseem Waseem and David Davidson BIBM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate Davidson BM and Hate", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": "Transformer ::: Neural ::: Neural ::: Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural : Neural", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": "F1. simple recall@1000.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.50.", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": "unanswerable (Document)\n\n\n\n\nQuestion: What is the size of the corpus?\n\n\nAnswer:unanswerable (Document)\n\n\nQuestion: What is the size of the corpus?\n\n\nAnswer:unanswerable (Document)\n\n\nQuestion: What is the size of the corpus?\n\n\nAnswer:unanswerable (Document)\n\n\nQuestion: What is the size of the corpus?\n\n\nAnswer:unanswerable (Document)\n\n\nQuestion: What is the size of the corpus?\n\n\nAnswer:un", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": "unanswerable\n9-layers unidirectional LSTM model (CE)\n\n\n\nAnswer:9-layers unidirectional LSTM model (CE)\n\n\n9-layers bidirectional LSTM model (CE)\n\n9-layers bidirectional LSTM model (CE)\n9-layers unidirectional LSTM model (CE)\n\n9-layers bidirectional LSTM model (CE)\n9-layers unidirectional LSTM model (CE)\n\n9-layers bidirectional LSTM model (CE", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": "professional translation (unanswerable)\n\n\n\n\nQuestion:What is the main goal of the paper?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the main hypothesis of the paper?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the main conclusion of the paper?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the main result of the paper?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the main", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": "end-to-to-end MRC (Multi-class Classification)\n\n\n\n\nAnswer:Knowledge Aided Reader (KAR) is an end-to-end MRC (Multi-class Classification) model.\n\n\n\nAcknowledgeledgments\n\nThis work is partially supported by a research donation from iFLY and a discovery grant from Natural Sciences and Engineering Research Council of Canada (NSERC).)\n\n\n\nAcknownowledgments\nThis work is partially supported by a research donation from iFLY and a discovery grant from Natural Sciences and", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": "Acknowledgments to improve the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the sensitivity of the", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": "Human-\n We collect a novel dialogue-based dataset of 1000,00000 characters of 100,000000 characters of 10,00000 characters of 10,0000 characters of 10,0000 characters of 10,0000 characters of 10,0000 characters of 10,0000 characters of 10,0000 characters of 10,0000 characters of 10,0000", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": "Reutureuters-8 dataset without stopstop words from BIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIBIB", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": "Table TABSTABSTABREFREF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": "Tables a mixture of context, we can see in tweets 3, 4, 5, 6, 7, 8, 9, 10, 111, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 221, 222, 23, 24, 25, 26, 27, 28, 29, 30, 31", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": "WebQ:WebQ (WebQ)\n\n\n\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:An improved relation relation extraction model\n\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:An improved relation extraction model\n\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:An improved relation extraction model\n\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:An improved relation extraction model\n\n\nQuestion:What is the main contribution of this paper?\n\n", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": "spelling reliable for spelling for some error types is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is their model is", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": "The authors crawl crawl over 2M tweets from twitter using GetOldl INLINE BIBBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBINBIN", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": "The global context refers to capture the semantic information of the whole document (i.e. global context) and the local context of a sentence (i.e. local context) BIBF: B1-EN: The global context of a sentence is the information of the whole document (i.e. global context) and the local context of a sentence (i.e. local context) BIBF: B1-EN: The global context of a sentence is the information of the whole document (i.e. global context) and the local context of a sentence (i.e. local context) BIB", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": "Knowledgeledgeledge Base Question Answering (KBQA) (Document)\n\n\n\n\nQuestion:What is the main focus of the article?\n\n\nAnswer:Knowledge Base QA (Document)\n\n\nQuestion:What is the main focus of the article?\n\n\nAnswer:Knowledge Base QA (Document)\n\n\nQuestion:What is the main focus of the article?\n\n\nAnswer:Knowledge Base QA (Document)\n\n\nQuestion:What is the main focus of the article?\n\n\nAnswer:Knowledge Base QA (", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": "They applied LDA and Gibbs to evaluate ISWC and WWW publications (DBIBIBLI)\n\n\n\n\nQuestion: What is the main goal of this paper?\n\n\nAnswer: The main goal of this paper is to present a taxonomy of recommendation systems based on LDA and evaluate ISWC and WW publications (DBIB)\n\n\n\nQuestion: What is the main goal of this paper?\n\n\nAnswer: The main goal of this paper is to present a taxonomy of recommendation systems based on LDA and evaluate ISWC and WW publications (DB)\n", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": "yes (unanswerable)\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the data enrichment method?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: (unanswerable)", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": "650.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": "unanswered by the BioASQ\n\n\n\n\nQuestion: What was the approach used for the factoid type questions?\n\n\nAnswer:Contextualization\n\n\nQuestion: What was the approach for the list type of questions?\n\n\nAnswer:Contextualization\n\n\nQuestion: What was the approach for the list of questions?\n\n\nAnswer:Contextualization\n\n\nQuestion: What was the approach for the list of questions?\n\n\nAnswer:Contextualization\n\n\nQuestion: What was the approach for the list of questions?\n\n\nAnswer:Contextualization", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": "0.28866622\n\n\n\n\nQuestion: What was their highest 'MRRRR' score?\n\n\nAnswer:0.61103\n\n\nQuestion: What was their highest 'MRR' score?\n\n\nAnswer:0.6103\n\n\nQuestion: What was their highest 'MR' score?\n\n\nAnswer:0.6103\n\n\nQuestion: What was their highest 'MR' score?\n\n\nAnswer:0.6103\n\n\nQuestion: What was their highest '", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": "BLEVoccurrecting the question based on the above article as concisely as you can, using a single phrase or sentence if possible. If the question can not be answered based on the information in the article, write \"unanswerable\" . If the question is a yes / no question, answer \"yes\" or \"no\" or \"unanswerable\" (Document[10]):\"Acknowledgments:We gratefully acknowledge the collaboration of Maija Paija Paija, Salja Salja, and the support of the Google Google Digital News Initiative Fund, the Academy", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": "unanswerable (unanswerable)\n\n\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer:unanswerable\n\n\nQuestion: What is the name of the dataset they used?\n\n\nAnswer:unanswerable\n\n\n", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": "Cyber (Cy)\nCy)\nCy\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:A novel human-in-the-loop approach for discovering inform informative keywords and their associated contexts\n\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:A novel human-in-the-loop for discovering informative keywords and their associated contexts\n\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:A novel human-in-the-loop for discovering informative keywords and their associated", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": "The end-to-end RQA system (IR)\n\n\n\n\nQuestion: What is the effectiveness of the RQE-based QA system?\n\n\nAnswer:The effectiveness of the RQE-based QA system\n\n\nQuestion: What is the effectiveness of the RQE-based QA system?\n\n\nAnswer:The effectiveness of the RQE-based QA system\n\n\nQuestion: What is the effectiveness of the RQE-based QA system?\n\n\nAnswer:The effectiveness of the RQE-", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": "Conditional Contentional Copy (CC) model\n\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:a hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hierarchical hier", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": "the Jacobian invertible condition for our neural network (INLINE1)\n\n\n\n\nQuestion: What is the Jacobian determinant?\n\n\nAnswer:the Jacobian determinant (INLINE1)\n\n\nQuestion: What is the Jacobian determinant?\n\n\nAnswer:the Jacobian determinant (INLINE1)\n\n\nQuestion: What is the Jacobian determinant?\n\n\nAnswer:the Jacobian determinant (INLINE1)\n\n\nQuestion: What is the Jacobian determinant?\n\n\nAnswer:the Jacobian determinant (INLINE1", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": "Logistic Regression (Logistic regression (LR) and Logistic (ML)\n\n\n\n\nQuestion: What is the main goal of the paper?\n\n\nAnswer: To propose a human-AI loop that iteratively iterates between human and AI to improve the performance of event detection\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: A novel human-AI that iteratively iterates between human and AI to improve the performance of event detection\n\n\n\nQuestion: What is the main problem of the paper?\n\n\nAnswer: The lack of a", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": "INLINE\n\n\n\n\nQuestion:what is the size of the real-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-world civil-", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": "MCScripts 1111100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": "Back- Back-Translation\n\n\n\n\n-Mix-Translation\n\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-Translation\n-Mix-", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": "significant improvement\n\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: novel dialogue\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: novel dialogue\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: novel dialogue\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: novel dialogue\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer: novel dialogue\n\n\nQuestion: What is the main contribution of this paper", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": "Arabic language is language and dialect is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is language is", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": "The authors show the total score achieved by the Seq2Seq model is much higher than the one achieved by the LSTM model, which is in turn much higher than the one achieved by the DQN model. (Section 5.2.2.2)\n\n\n\nAnswer:\n\nAnswer:\n\nThe authors show that their learned Seq2Seq model generalizes better to unseen games by comparing the scores achieved by the Seq2Seq model to the scores achieved by the LSTM model and the DQN model. The Seq2Seq model achieves a much higher score than the LSTM", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": "To investigate gender bias in society (Document)\n\n\n\n\nQuestion: What is the main conclusion of the paper?\n\n\nAnswer: Understanding (Document)\n\n\nQuestion: What is the main goal of the paper?\n\n\nAnswer: Understanding (Document)\n\n\nQuestion: What is the main conclusion of the paper?\n\n\nAnswer: Understanding (Document)\n\n\nQuestion: What is the main goal of the paper?\n\n\nAnswer: Understanding (Document)\n\nQuestion: What is the main conclusion of the paper?\n\n\nAnswer: Understanding (", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": "A predictive conversation (R4)\n\n\n\n\nQuestion: What is the main goal of the paper?\n\n\nAnswer:predictive model (R4)\n\n\nQuestion: What is the main question they answer?\n\n\nAnswer: predictive model (R4)\n\n\nQuestion: What is the main question they answer?\n\n\nAnswer: predictive model (R4)\n\n\nQuestion: What is the main question they answer?\n\n\nAnswer: predictive model (R4)\n\n\nQuestion: What is the main question they answer?\n\n\nAnswer", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": "yes\n\n\n\n\n\"The dataset is split into three subsets: (1) train, (2) validation, and (3) test. The train set is used for training the model, the validation set is used to check the performance of the model, and the test set is used to evaluate the final model. The train set is composed of 1,0000 papers, the validation set is composed of 100 papers, and the test set is composed of 100 papers.\"\n\n\n\nAnswer:\n\nyes\n\nAnswer:\n\n\nyes\n\nAnswer:\n", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": "MPADAMBERT BIBER\n\n\n\n\nArticle:Introduction\nThe concept of message passing over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over message over", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": "by perturbation of the intermediate of the intermediate results of Chinese results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate results of the intermediate", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": "Wikipedia\n\n\n\n\n\nWikipedia\n\n\nAnswer:\nWikipedia\n\n\nAnswer:\n\nWikipedia\n\n\nAnswer:\n\nWikipedia\n\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:\n\nWikipedia\n\nAnswer:", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": "yes (unanswerable)\n\n\n\n\nQuestion: what is the size of the dataset?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: what is the size of the monasite?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: what is the size of the corpus?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: what is the size of the parallel corpus?\n\n\nAnswer: (unanswerable)\n\n\nQuestion: what is the size of the parallel corpus?\n\n\nAnswer: (unanswer", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": "EuroParallel Europarl 2007 2013 2014 2015 2016 2017 2018 2019 2020 2021 20222 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 20333 2034 2035", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": "yes (MAR)\n\n\n\n\nQuestion: What is the F-score?\n\nAnswer: (MA)\n\n\nQuestion: What is the F-score?\nAnswer: (MA)\n\n\nQuestion: What is the F-score?\nAnswer: (MA)\n\n\nQuestion: What is the F-score?\nAnswer: (MA)\n\n\nQuestion: What is the F-score?\nAnswer: (MA)\n\n\nQuestion: What is the F-score?\nAnswer: (MA)\n\n\nQuestion: What is the F-score?", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": "\n \"A second - order co-order co-occurrence matrix is a matrix that shows the co-occurrence of a word with another word in a corpus . It is a generalization of the first - order co-occurrence matrix, which shows the co-occurrence of a word with another word in the same document . The second - order co-occurrence matrix is a matrix that shows the co-occurrence of a word with another word in a corpus . It is a generalization of the first - order co-occurrence matrix, which shows the co-occurrence of a word with another word", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": "precision, recall, F1-measure, F1-measure, and F1-measure (Document)\n\n\n\n\nQuestion: what is the purpose of the paper?\n\n\nAnswer: to introduce a novel legal judgment judgment prediction task and propose a novel framework for it (Document)\n\n\n\nQuestion: what is the main contribution of the paper?\n\n\nAnswer: a novel legal judgment prediction task and propose a novel framework for it (Document)\n\n\n\nQuestion: what is the main task of the paper?\n\nAnswer: to introduce a novel legal judgment prediction task and propose a novel", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": "unanswerable (Document)\n\"The summarized Sera-Discandid results are based on the TACL-2013 dataset, which consists of 100000 English articles from the PubMedline database. The TACL-2013 dataset is a subset of the TACL-2012 dataset, which consists of 10000 English articles from the Pubmed database. The TACL-2012 dataset is a subset of the TACL-20111 dataset, which consists of 10000", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": "by their predicted difficulty (difficulty) (Document[10]):\"We operationalize the concept of annotation difficulty and show how it can be used to improve the quality of the annotated data . We first define a difficulty score for each instance and then use it to weight the annotation data . We show that this simple approach can improve the performance of the downstream tasks.\"\n\n\n\nQuestion: How do they define difficulty?\n\n\nAnswer: by inter-annotator agreement (Document[10]\":\"We then define a difficulty score for each instance and then use it to weight the annotation data .", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": "2,1000000\n\n\n\n\nAnswer: 2,1000\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer: 2,100\n\n\nAnswer:", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": "yes\n\n\n\n\n\nQuestion: What is the best performing model for the task?\n\n\nAnswer: ELMo with encoder\n\n\nQuestion: What is the best performing model for the task?\n\n\nAnswer: ELMo with encoder\n\n\nQuestion: What is the best performing model for the task?\n\n\nAnswer: ELMo with encoder\n\n\nQuestion: What is the best performing model for the task?\n\n\nAnswer: ELMo with encoder\n\n\nQuestion: What is the best performing model for the task?\n\n\nAnswer: ELMo with enc", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": "yes (see Section SECREF10)\n\n\n\n\nAnswer: \"We use the same pre-trained embeddings for the input and output words. We also use the same pre-trained embeddings for the input and output words. We also use the same pre-trained embeddings for the input and output words.\"\n\n\n\nAnswer: yes\n\n\nAnswer: (see Section SE10)\n\n\"We use the same pre-trained embeddings for the input and output words. We also use the same pre-trained embeddings for the", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": "ROGold (ROU)GUE (G)e (RO)G (E)\n\n\n\n\nQuestion:What is the main contribution of the paper?\n\n\nAnswer:The pipeline is a full-fledged pipeline that takes an input text and generates an abstract in a human-like language.\n\n\n\nQuestion:What is the main contribution of the paper?\n\n\nAnswer:The pipeline is a full-fledged pipeline that takes an input text and generates an abstract in a human-like language.\n\n\nQuestion:What is the main contribution of the paper?\n", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": "(1) Naive: Naive: A non-domain-adaptive: A non-domain-adaptive: (2) mSDA: A state-of-the-art: A state-of-the-art: (3) ADAN: A domain-adaptive: A domain-adaptive: (4) FAN: A feature-adaptive: A feature-adaptive: (5) DAS: A domain-adaptive: A domain-adaptive: (6) DAS: A domain-adaptive: A domain-", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": "590.0%\n\n\n\n\nQuestion: What is the difference between the accuracy of the visual model and the text model?\n\n\nAnswer:0.0\n\n\nQuestion: What is the difference between the accuracy of the visual model and the text model?\n\n\nAnswer:0.0\n\n\nQuestion: What is the difference between the accuracy of the visual model and the text model?\n\n\nAnswer:0.0\n\nQuestion: What is the difference between the accuracy of the visual model and the text model?\n\n\nAnswer:0.0\n\nQuestion:", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": "word2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": "US (US) mainstream (US)\n\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:a multi-layered approach to detect disinformation\n\n\nQuestion: What is the main goal of the paper?\n\n\nAnswer: to detect disinformation\n\n\nQuestion: What is the main method used in the paper?\n\n\nAnswer: a multi-layered approach to detect disinformation\n\n\nQuestion: What is the main result of the paper?\n\n\nAnswer: a multi-layered approach to detect disinformation\n\n\nQuestion: What", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": "The Changes that the political party and the political party of the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and the political party and", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": "They show that a majority of the questions that the system could not answer correctly were in fact answerable by humans (Document[10]):\"The results of the human study suggest that there is still space for improvement in the system, as a system that would answer all the questions correctly would achieve an accuracy of 92.2% on the NE test set and 92.4% on the NE test set, which is still far from the 96% that humans achieve (Document[10]):\"The results of the human study suggest that there is still space for improvement in the system, as a", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": "F1. macro F1 (Section SECREF)\n\n\n\n\nQuestion: What is the macro-averaged F1 score?\n\n\nAnswer: the average of the precision and recall scores over all the classes (Section SECRE)\n\n\n\nQuestion: What is the macro-averaged F1 score?\n\n\nAnswer: the average of the precision and recall scores over all the classes (Section SECRE)\n\n\n\nQuestion: What is the macro-averaged F1 score?\n\n\nAnswer: the average of the precision and recall scores over all the classes (Section SE", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": "unanswerable\nYes\n\n\n\n\"The collection of the medical domain-specific resources is based on the PubMedline database, which is the largest and most comprehensive database of biomedical literature. The collection of the medical domain-specific resources is based on the Publine database, which is the largest and most comprehensive database of biomedical literature.\"\n\n\n\nAnswer:Yes\n\n\nAnswer:Yes\n\n\"The collection of the medical domain-specific resources is based on the Publine database, which is the largest and most comprehensive database of biomedical literature.\"\n\n\n\nAnswer", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": "5K\nThe Wikipedia dataset consists of articles from English Wikipedia, with the corresponding article text and the corresponding screenshot of the article . The text is obtained from the Wikipedia API, and the screenshot is obtained by crawling the Wikipedia website.\n\n\n\nQuestion: What is the purpose of the paper?\n\n\nAnswer:The purpose of the paper is to explore the possibility of using visual features to improve the performance of NLP models.\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer:The main contribution of the paper is to show that visual features can be used to improve the", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": "unanswered\n\n\n\n\n\nQuestion:Do they recommend using back-translation?\n\n\nAnswer:unanswerable\n\n\nQuestion: Do they recommend using machine translation?\n\n\nAnswer:unanswerable\n\n\nQuestion: Do they recommend using human translation?\n\n\nAnswer:yes\n\n\nQuestion: Do they recommend using machine translation?\n\nAnswer:unanswerable\n\nQuestion: Do they recommend using human translation?\n\n\nAnswer:yes\n\nQuestion: Do they recommend using machine translation?\n\nAnswer:unanswerable\n\nQuestion: Do they recommend using", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": "Coverage of LiF1\n\n\n\n\nQuestion: What is the main contribution of this paper? \n\n\nAnswer:Answer:F1\n\n\nQuestion: What is the main contribution of this paper? \n\n\nAnswer:Answer:F1\n\nQuestion: What is the main contribution of this paper? \n\n\nAnswer:Answer:F1\n\nQuestion: What is the main contribution of this paper? \n\n\nAnswer:Answer:F1\n\nQuestion: What is the main contribution of this paper? \n\nAnswer:Answer:F1\n\n\nQuestion", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": "Inspectively driven (BIB)\n\n\n\n\nQuestion: What are the authors's goals in this article?\n\n\nAnswer:to help (B)\n\n\nQuestion: What are the authors's three primary goals in this article?\n\n\nAnswer:to help (B)\n\n\nQuestion: What are the authors's three goals in this article?\n\n\nAnswer:to help (B)\n\n\nQuestion: What are the authors's three goals in this article?\n\n\nAnswer:to help (B)\n\n\nQuestion: What are the authors'", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": "Reddit is a dataset of 10,00000 Reddit subreddit posts from the /r/politics subreddit, which was active from 2014-012-01 to 2015-01-01 (Document[1]):\"The dataset consists of 0,000 Reddit posts from the /r/politics subreddit, which was active from 2014-01-01 to 2015-01-01 (Document[1]):\"The dataset consists", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": "Energy (Energy)\n\n\n\n\nQuestion:What is the best performing model?\n\n\nAnswer: + News (BiLSTM) + NRA (BiLSTM + NRA)\n\n\n\nQuestion:What is the best performing model?\n\nAnswer: + News (BiLSTM) + NRA (BiLSTM + NRA)\n\n\n\nQuestion:What is the best performing model?\n\nAnswer: + News (BiLSTM) + NRA (BiLSTM + NRA)\n\n\n\nQuestion:What is the", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": "The authors are schollingers\n\n\n\n\n\nQuestion: What is the main point of the article?\n\n\nAnswer: Computational\n\n\nQuestion: What is the main point of the article?\n\n\nAnswer: Computational\n\n\nQuestion: What is the main point of the article?\n\n\nAnswer: Computational\n\n\nQuestion: What is the main point of the article?\n\n\nAnswer: Computational\n\n\nQuestion: What is the main point of the article?\n\n\nAnswer: Computational\n\n\nQuestion: What is the main point of the article", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": "SVMa) Support vector machine learning (SVM) is a supervised learning method that uses a labeled training set to train a model that maps inputs to outputs. The labeled training set is typically a set of examples, so in the case of sentiment analysis, it is a set of examples with their corresponding labels. The model is trained by minimizing the difference between the predicted output and the actual output. The difference is typically measured by a loss function. The most common loss function is cross-entropy (CE), which measures the difference between the predicted distribution and the actual distribution.\n\n\n\nAnswer:unanswer", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": "yes\n\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:\nbridging dehuman bias and improving the understanding of dehumanized language\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:\nbridging dehuman bias and improing the understanding of dehumanized language\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:\nbridging dehuman bias and improing the understanding of dehumanized language\n\n\nQuestion: What is the main contribution of this paper?\n\nAnswer:\nbridging", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": "Convers the state of the art on conversational systems and their interactions with humans\n\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: the main contribution of the paper is a hybrid architecture that combines the best of both worlds\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: the main contribution of the paper is a hybrid architecture that combines the best of both worlds\n\n\n\nQuestion: What is the main contribution of the paper?\n\n\nAnswer: the main contribution of the paper is a hybrid architecture", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": "the corpus a novel corpus of state speeches and votes from the United Nations General Assembly and the Security Council, as well as the General Assembly's Third Committee Reports and the General Assembly's Annual Reports (Document 1).)\n\n\n\n\nQuestion: What is the main goal of the paper?\n\n\nAnswer: to estimate the effect of the United Nations General Assembly and the Security Council on the resolution of the General Assembly's Third Committee Reports and the General Assembly's Annual Reports (Document 1).)\n\n\n\nQuestion: What is the main method used", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": "Doc2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": "argument components (1) the largest feature set of argument components (2) the most important argument components (3) the most frequent argument components (4) the most frequent argument components (5) the most frequent argument components (6) the most frequent argument components (7) the most frequent argument components (8) the most frequent argument components (9) the most frequent argument components (10) the most frequent argument components (11) the most frequent argument components (12) the most frequent argument components (13) the most frequent argument components (14) the most frequent argument components (15) the most frequent", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": "yes (unanswerable)\n\n\n\n\nQuestion: Do they use any other languages?\n\n\nAnswer: no (unanswerable)\n\n\nQuestion: Do they use any other languages?\n\n\nAnswer: no (unanswerable)\n\n\nQuestion: Do they use any other languages?\n\n\n\nAnswer: no (unanswerable)\n\n\nQuestion: Do they use any other languages?\n\n\n\nAnswer: no (unanswerable)\n\nQuestion: Do they use any other languages?\n\n\n\nAnswer: no (unanswerable)\n\nQuestion", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": "unanswer unanswerable\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:Answer:unanswerable\n\n\nQuestion: What is the main challenge of MPC?\n\n\nAnswer:Answerable\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:unanswerable\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:unanswerable\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:unanswerable\n\nQuestion: What is the main contribution of this paper?", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": "unanswerable\n\n\n\n\nThe authors use the NRC-40000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": "a state of a node\n\n\n\n\nQuestion: What is the difference between a node and a state?\n\nAnswer:a node\n\n\nWhat is the difference between a node and a state?\nAnswer:a node\n\n\nWhat is the difference between a node and a state?\nAnswer:a node\n\n\nWhat is the difference between a node and a state?\nAnswer:a node\n\n\nWhat is the difference between a node and a state?\nAnswer:a node\n\n\nWhat is the difference between a node and a state?\nAnswer:a node\n\n\nWhat", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": "The data was collected from various sources, including professional news articles, blogs, and social media (e.g., Twitter, Facebook, and YouTube) (Document[10]):\"The corpus consists of 1,0000 documents, which were collected from various sources, including professional news articles, blogs, and social media (e.g., Twitter, Facebook, and YouTube) (Document[10]):\"The corpus consists of 1,000 documents, which were collected from various sources, including professional news articles, blogs, and social media (e.g., Twitter", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": "by using the NLT-LGBTQ-T-LGBT-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": "yes\n\n\n\n\n\n\n\nQuestion: What are the main challenges of working with computational methods?\n\n\nAnswer:\n\nunanswerable\n\n\nQuestion: What are the main challenges of working with computational methods?\n\n\nAnswer:\n\nunanswerable\n\n\nQuestion: What are the main challenges of working with computational methods?\n\n\nAnswer:\n\nunanswerable\n\n\nQuestion: What are the main challenges of working with computational methods?\n\n\nAnswer:\n\nunanswerable\n\n\nQuestion: What are the main challenges of working with", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": "thorn overlap between large-scale issues not always at the forefront of discussions\n\n\n\n\nQuestion: What are the goals of the article?\n\n\nAnswer:to shed light on thorny issues not always at the forefront of discussions\n\n\n\nQuestion: What are the three primary goals of the article?\n\n\nAnswer:to shed on thorny issues not always at the forefront of discussions\n\n\n\nQuestion: What are the three primary goals of the article?\n\n\nAnswer:to shed on thorny issues not always at the forefront of discussions", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": "accuracy (i)\n\n\n\n\nQuestion: What is the main contribution of this paper?\n\n\nAnswer:The main contribution of this paper is the presentation of a hybrid architecture for MPC, which is able to provide a high level of accuracy and scalability.\n\n\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:The main contribution of this paper is the presentation of a hybrid architecture for MPC, which is able to provide a high level of accuracy and scalability.\n\n\nQuestion:What is the main contribution of this paper?\n\n\nAnswer:", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": "yes\n\n\n\n\"The most commonly used approach to estimate states' preferences is to count the number of times a state has voted for a particular resolution in the UN General Assembly or the Security Council. This is a crude and uninformative measure of a state's preferences, because it does not take into account the relative importance of the resolutions in which a state votes, and it does not take into account the fact that a state may vote for a resolution in order to prevent it from passing, rather than in order to support it. In addition, the number of votes is not a good measure of a", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": "\"Annot all the actual effort of annotating argumentative structures and argumentative strategies is a function of the register of the text and the domain of the discourse\" (p. 10)\n\n\n\nAnswer:\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n\nAnswer:\n", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": "Multi- Multi- The Multi-lingual annotation: We annotated the datasets in a multi-lingual fashion, which means that we annotated the same set of word pairs in all 12 languages.\n-Inter-lingual: We annotated the datasets in an inter-lingual fashion, which means that we annotated the same set of word pairs in different languages.\n\n\n\nQuestion: What is the purpose of the Multi-lingual annotation?\n\n\nAnswer: The purpose of the Multi-lingual annotation is to ensure that the annotations are consistent across different languages.\n\n\nQuestion:", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": "(1) the largest linguistic features of online argumentation (2) linguistic features of argumentation (3) linguistic features of argumentation (4) linguistic features of argumentation (5) linguistic features of argumentation (6) linguistic features of argumentation (7) linguistic features of argumentation (8) linguistic features of argumentation (9) linguistic features of argumentation (10) linguistic features of argumentation (11) linguistic features of argumentation (12) linguistic features of argumentation (13) linguistic features of argumentation (14)", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": "Multi typically diverse typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typologically typ", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}
